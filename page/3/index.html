<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>detect - Pursue inner peace</title><meta name="author" content="Richard,detect0530@gmail.com"><meta name="copyright" content="Richard"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="If you can&#39;t explain it simply, you don&#39;t understand it well enough.">
<meta property="og:type" content="website">
<meta property="og:title" content="detect">
<meta property="og:url" content="https://detect42.github.io/page/3/index.html">
<meta property="og:site_name" content="detect">
<meta property="og:description" content="If you can&#39;t explain it simply, you don&#39;t understand it well enough.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://detect42.github.io/img/ff.jpg">
<meta property="article:author" content="Richard">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://detect42.github.io/img/ff.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://detect42.github.io/page/3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":1000},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'detect',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-01-21 11:14:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/1.css"><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/ff.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">78</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/topimg.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="detect"><span class="site-name">detect</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">detect</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/detect42" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:detect0530@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/96345fc2.html" title="RL_toolbox">RL_toolbox</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-03-14T13:29:59.000Z" title="Created 2024-03-14 21:29:59">2024-03-14</time></span></div><div class="content"></div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/61815765.html" title="Proximal Policy Optimization(PPO)">Proximal Policy Optimization(PPO)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-03-14T07:19:13.000Z" title="Created 2024-03-14 15:19:13">2024-03-14</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content">
 Proximal Policy Optimization(PPO) 
 detect0530@gmail.com 
Background: PG and TRPO
Policy Gradient
我们使用策略网络进行决策，对于每一版的policy network，我们使用on-policy的方法获得数据，并使用这些数据更新网络，得到下一版的policy network。
更新过程其实就是根据Reward来调整给每一个action分配的权重。

Tips:


增加一个基线
原始算法我们用reward的大小作为引导，但是reward设计的不好时，由于采取动作都会有奖励，一是有noise，二是这样引导会错过一些未访问过的good action。于是我们引入基线（一般设置为V(s),表示所有采样序列的平均奖励），高于基线，给正奖励；低于基线，给负奖励。



折扣因子
降低未来reward的权重，只需要对奖励序列的求和计算增加一个gamma因子即可。


优势函数
回顾之前的算法，对于一个采样序列中的数据点，我们都是用相同的R(γ)R(\gamma)R(γ)作为系数，这样很粗糙。实际上好 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/10a2bc0d.html" title="DDPG">DDPG</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-03-06T14:48:35.000Z" title="Created 2024-03-06 22:48:35">2024-03-06</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content"> Deep Deterministic Policy Gradient 
Background
在过去的DQN实践中，我们更多的采用神经网络直接对状态s进行近似，映射分数到动作空间里然后再根据得分选择动作。这种方法在离散动作空间中表现良好，但是在连续动作空间中表现不佳。因为在连续动作空间中，动作空间的维度很高，而且动作空间的连续性使得我们无法直接使用神经网络来近似动作空间。因此，我们需要一种新的方法来解决这个问题。
Quick Facts

DDPG is an off-policy algorithm.
DDPG can only be used for environments with continuous action spaces.
DDPG can be thought of as being deep Q-learning for continuous action spaces.

Key Equations
我们从两个角度理解DDSG，一个是Q-learning的角度，另一个是策略梯度的角度。
Q-learning角度
L(ϕ,D)=E(s,a,r,s′,d)∼P[( ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/9c0b7a7e.html" title="Dueling-DQN">Dueling-DQN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-02-29T11:43:13.000Z" title="Created 2024-02-29 19:43:13">2024-02-29</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content">
 Dueling DQN 
Abstract
我们评估两个东西，一个是状态价值，一个是动作优势函数。在动作价值接近的时候，会很work。

为什么要采用对偶网络结构？
其实动机很简单：很多游戏的Q值，只受当前状态影响，无论采取什么动作区别不大。如下图所示：

这是Atari game中的一个赛车游戏，Value表示状态价值，Advantage表示动作优势值，图中黄色部分表示注意力。当前方没有车辆时，智能体左右移动并没有影响，说明动作对Q值没有影响，但是状态对Q值很有影响。从上面两幅图可以看出，Value更加关注远方道路，因为开的越远，对应的状态值越大；Advantage没有特别注意的地方，说明动作没有影响。当前方存在车辆阻挡时，智能体的动作选择至关重要，说明动作对Q值存在影响，同样状态对Q值也会存在影响。从下面两幅图可以看出，Value同样更加关注远方道路，但是Advantge此时会关注前方车辆，因为如果不采取相应动作，智能体很有可能会发生碰撞，分数就会很低。对偶网络思想符合很多场景的设定。
可以看到，状态函数和价值函数关注的是不一样的东西。
定义优势函数：
Aπ=Qπ(s,a)−V ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/8b04483f.html" title="Prioritized Experience Replay">Prioritized Experience Replay</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-02-29T11:32:45.000Z" title="Created 2024-02-29 19:32:45">2024-02-29</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content">
 Prioritized Experience Replay 
Experience replay的演化
online RL:缺点：经验之间是correlated的，不满足stochastic gradient-decent的要求。另外，有用的好经验被使用一次后就遗忘了。
普通的experience replay可以记下经验，然后抽样更新参数，这样一方面减少了对打量经验的需求，转而用更多的计算力和内存（经常比RL agent和环境交互更cheaper）
而Prioritized experience replay further liberates the agents from considering transitions with the same frequency that they are experienced.

一些tricks
总的来说，用TD error来衡量经验的重要性，但是这样有两个问题：
(a) loss of diversity，影响stochastic gradient descent的性能。
(b) introduce bias，需要我们用impor ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/706535e8.html" title="DDQN">DDQN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-02-29T08:04:32.000Z" title="Created 2024-02-29 16:04:32">2024-02-29</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content">
 Double DQN 
DQN的overestimation的问题
众所周知DQN有substantial overestimations的问题
乐观估计在某种程度上是我们鼓励在不确定时的探索技巧，但是因为DQN中max操作和各种噪音、误差的原因，这种乐观估计不是uniform或者集中在我们希望的status上，会造成性能退化。
Atari游戏很适合DQN，因为环境是deterministic，同时deep nn可以很好地渐进拟合Q值。

我们依然用原nn评估用哪一个动作，但是计算这个动作的最后TD估计时，我们用另一个nn来计算。这样可以减少overestimation的问题。
errors and noises
errors and noises无处不在，包括environment,function approximation,non-stationary，这是很显然的，因为我们不知道true values，任何的方法都有不准确性。即是没有bias，uniform是0，也会有variance。这些都会导致overestimation。


数学上bias和variance导致的o ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/18a6c10f.html" title="DS作业汇报 Fibonacci堆">DS作业汇报 Fibonacci堆</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-02-16T10:59:51.000Z" title="Created 2024-02-16 18:59:51">2024-02-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NJU-course/">NJU course</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/NJU-course/Data-structure/">Data structure</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span></div><div class="content"> DS作业汇报 Fibonacci堆 
 detect0530@gmail.com 
探究Fibonacci堆对dijkstra算法的优化效果

复杂度分析，与常见堆结构的理论横向对比
实现Fibonacci堆
验证Fibonacci堆的正确性

利用qt实现可视化效果，方便调试
设定check函数，自动检测堆性质以及双向链表的正确性
与其他堆以及stl提供的priority_queue进行对拍比较


将正确性得到保证的Fibonacci堆应用到dijkstra算法中，并在随机&amp;高压数据集上进行测试，并记录实验结构
分析实验结果，得出结论

理论复杂度对比



操作 \ 数据结构
配对堆
二叉堆
左偏树
二项堆
斐波那契堆




插入（insert）
O(1)O(1)O(1)
O(log⁡n)O(\log n)O(logn)
O(log⁡n)O(\log n)O(logn)
O(log⁡n)O(\log n)O(logn)
O(1)O(1)O(1)


查询最小值（find-min）
O(1)O(1)O(1)
O(1)O(1)O(1)
O(1)O(1)O(1)
O(1)O ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/84628cd6.html" title="DQN coding exercise">DQN coding exercise</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-02-03T11:47:25.000Z" title="Created 2024-02-03 19:47:25">2024-02-03</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content"> DQN theory and practice 
 detect0530@gmail.com 
以下是DQN完成atari游戏Pong的代码实现，包括了完整的朴素DQN实现，以及experience replay和target network的改进。代码实现基于PyTorch和OpenAI Gym。
并使用Chatgpt生成相应的代码注释，以及各个package api的介绍。

123USE_CUDA = torch.cuda.is_available()dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensorVariable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)
这段代码主要是用于检查是否可用CUDA（用于GPU加速），然后根据可用性设置相应的数据类型和变量。


USE_C ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/cb58cbf7.html" title="DQN experiment: Pong">DQN experiment: Pong</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-02-03T07:39:32.000Z" title="Created 2024-02-03 15:39:32">2024-02-03</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/RL/">RL</a></span></div><div class="content"> DQN theory and practice 
 detect0503@gmail.com 
original paper: Playing Atari with Deep Reinforcement Learning

Abstract
This is a simple experiment to train a DQN agent to play atari game Pong. This paper proposes a novel approach, directly using the entire game screen as input for the model. The model autonomously determines what features to extract, and even the specific features it learns are not of primary concern. What matters is that the model can make correct actions in various states,  ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/post/21249fb3.html" title="演化算法HW4 BBO黑箱芯片放置问题">演化算法HW4 BBO黑箱芯片放置问题</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-01-26T05:38:17.000Z" title="Created 2024-01-26 13:38:17">2024-01-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NJU-course/">NJU course</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/NJU-course/HSEA/">HSEA</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span></div><div class="content"> Macro placement by black-box optimization 
 detect0530@gmail.com 

1 问题分析
通过阅读发下来的code，发现需要我调整的黑箱问题是，给定一组长度为dim，有上下界的整数序列。
实例代码使用随机搜索的方法，通过不断生成随机数列来更新最优答案。
由于BBO已经为我们设计好了评价黑盒，我们只需要考虑如何在这组数列上进行演化算法即可。
2 基本的演化算法设计 &amp; 比较不同mutation,crossover的性能
2.1 种群设置
由于单次黑盒评估运算量巨大（2-5s），我们需要尽可能减少黑盒评估次数。
所以种群大小一开始定为10
2.2 selection
初始算法中，我将随机从种群中选出父代。
2.3 mutaion

随机选择两个位置进行位置交换
以概率p1对每个位置进行随机变化

2.4 crossover
选出两个父代后：

随机选择断点，然后将两个父代的断点两侧进行交换
以概率p2对每个位置进行父代交换

survival selection
以n+n策略进行精英保留，保存最优的n个个体
设计好基本的演 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/#content-inner">8</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/ff.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Richard</div><div class="author-info__description">If you can't explain it simply, you don't understand it well enough.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">78</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/detect42"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/detect42" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:detect0530@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">blog is buliding!</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/5cb6a14b.html" title="Network Compression">Network Compression</a><time datetime="2025-01-21T03:13:38.000Z" title="Created 2025-01-21 11:13:38">2025-01-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/6e7ac1bd.html" title="Domain Adaptation">Domain Adaptation</a><time datetime="2025-01-19T09:56:38.000Z" title="Created 2025-01-19 17:56:38">2025-01-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/edd9f9ab.html" title="Unsurpervised Learning">Unsurpervised Learning</a><time datetime="2025-01-17T14:55:48.000Z" title="Created 2025-01-17 22:55:48">2025-01-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/8f0c2e6e.html" title="Energy-Based Model Training and Implicit Inference">Energy-Based Model Training and Implicit Inference</a><time datetime="2024-10-19T15:54:18.000Z" title="Created 2024-10-19 23:54:18">2024-10-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/4d712855.html" title="SQL">SQL</a><time datetime="2024-10-17T15:10:53.000Z" title="Created 2024-10-17 23:10:53">2024-10-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/d5d94bd1.html" title="Deep Generative Model">Deep Generative Model</a><time datetime="2024-10-10T07:44:35.000Z" title="Created 2024-10-10 15:44:35">2024-10-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/61815766.html" title="MOPO">MOPO</a><time datetime="2024-10-09T07:19:13.000Z" title="Created 2024-10-09 15:19:13">2024-10-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/4668f2fa.html" title="COMBO">COMBO</a><time datetime="2024-10-08T15:07:25.000Z" title="Created 2024-10-08 23:07:25">2024-10-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/653763f0.html" title="About me">About me</a><time datetime="2024-06-01T03:14:28.000Z" title="Created 2024-06-01 11:14:28">2024-06-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/35afb456.html" title="随笔-big city">随笔-big city</a><time datetime="2024-05-18T16:34:05.000Z" title="Created 2024-05-19 00:34:05">2024-05-19</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            <a class="card-more-btn" href="/categories/" title="More">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DL/"><span class="card-category-list-name">DL</span><span class="card-category-list-count">13</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DL/Lee-s-HW/"><span class="card-category-list-name">Lee's HW</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DL/Lee-s-notes/"><span class="card-category-list-name">Lee's notes</span><span class="card-category-list-count">11</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DL/code/"><span class="card-category-list-name">code</span><span class="card-category-list-count">1</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Math/"><span class="card-category-list-name">Math</span><span class="card-category-list-count">1</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Math/Bayesian-Network-and-MCMC/"><span class="card-category-list-name">Bayesian Network and MCMC</span><span class="card-category-list-count">1</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NJU-course/"><span class="card-category-list-name">NJU course</span><span class="card-category-list-count">11</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NJU-course/Crypto/"><span class="card-category-list-name">Crypto</span><span class="card-category-list-count">1</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/GPT/" style="font-size: 1.1em; color: #999">GPT</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 1.37em; color: #99a4b2">机器学习</a> <a href="/tags/resume/" style="font-size: 1.1em; color: #999">resume</a> <a href="/tags/%E5%AE%9E%E4%B9%A0/" style="font-size: 1.1em; color: #999">实习</a> <a href="/tags/Quant/" style="font-size: 1.1em; color: #999">Quant</a> <a href="/tags/linux/" style="font-size: 1.1em; color: #999">linux</a> <a href="/tags/python/" style="font-size: 1.23em; color: #999ea6">python</a> <a href="/tags/ML/" style="font-size: 1.23em; color: #999ea6">ML</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">神经网络</a> <a href="/tags/OS/" style="font-size: 1.1em; color: #999">OS</a> <a href="/tags/RL/" style="font-size: 1.5em; color: #99a9bf">RL</a> <a href="/tags/git/" style="font-size: 1.1em; color: #999">git</a> <a href="/tags/vim/" style="font-size: 1.1em; color: #999">vim</a> <a href="/tags/HW/" style="font-size: 1.17em; color: #999c9f">HW</a> <a href="/tags/note/" style="font-size: 1.1em; color: #999">note</a> <a href="/tags/Metabit/" style="font-size: 1.1em; color: #999">Metabit</a> <a href="/tags/DS/" style="font-size: 1.1em; color: #999">DS</a> <a href="/tags/hexo/" style="font-size: 1.1em; color: #999">hexo</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 1.3em; color: #99a1ac">实验报告</a> <a href="/tags/diffusion/" style="font-size: 1.17em; color: #999c9f">diffusion</a> <a href="/tags/algorithm/" style="font-size: 1.43em; color: #99a6b9">algorithm</a> <a href="/tags/GAN/" style="font-size: 1.1em; color: #999">GAN</a> <a href="/tags/catalog/" style="font-size: 1.1em; color: #999">catalog</a> <a href="/tags/c/" style="font-size: 1.17em; color: #999c9f">c++</a> <a href="/tags/%E9%9A%8F%E7%AC%94/" style="font-size: 1.17em; color: #999c9f">随笔</a> <a href="/tags/tool/" style="font-size: 1.17em; color: #999c9f">tool</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">January 2025</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">October 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">June 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">May 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">April 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">March 2024</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">February 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">January 2024</span><span class="card-archive-list-count">16</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">December 2023</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">November 2023</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">October 2023</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">September 2023</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">July 2023</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">June 2023</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">March 2023</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">78</div></div><div class="webinfo-item"><div class="item-name">Run time :</div><div class="item-count" id="runtimeshow" data-publishDate="2023-03-23T12:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">224k</div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-01-21T03:14:38.027Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/topimg.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Richard</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></body></html>