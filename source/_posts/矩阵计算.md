---
title: 矩阵计算
tags: nju
catagories: nju
abbrlink: 725267af
date: 2025-06-09 23:13:28
---
## 矩阵特征值

<img src="矩阵计算/image.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-1.png" alt="" width="70%" height="70%">

## 矩阵的迹

<img src="矩阵计算/image-2.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-3.png" alt="" width="70%" height="70%">

## 矩阵的秩

<img src="矩阵计算/image-4.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-5.png" alt="" width="70%" height="70%">


## 内积and范数

<img src="矩阵计算/image-6.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-7.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-8.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-9.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-10.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-11.png" alt="" width="70%" height="70%">

一个比较重要的点：
<img src="矩阵计算/image-12.png" alt="" width="70%" height="70%">
说明范数之间是有limit的，有时一个范数很难，我们可以转换为最小化另一个容易处理的范数来solve。

<img src="矩阵计算/image-13.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-14.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-15.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-16.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-17.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-18.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-19.png" alt="" width="70%" height="70%">



## 正定矩阵


## 正交矩阵

<img src="矩阵计算/image-20.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-22.png" alt="" width="70%" height="70%">

正交矩阵重要性质：
<img src="矩阵计算/image-23.png" alt="" width="70%" height="70%">

## 三角矩阵

<img src="矩阵计算/image-24.png" alt="" width="70%" height="70%">



对于正定矩阵可以有cholesky分解：

<img src="矩阵计算/image-25.png" alt="" width="70%" height="70%">

这个方法可以用于采样协方差矩阵：
<img src="矩阵计算/image-26.png" alt="" width="70%" height="70%">

## 范德蒙矩阵

<img src="矩阵计算/image-27.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-28.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-29.png" alt="" width="70%" height="70%">

## 傅里叶矩阵

<img src="矩阵计算/image-30.png" alt="" width="70%" height="70%">

## 特征值分解

<img src="矩阵计算/image-21.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-31.png" alt="" width="70%" height="70%">

所有像$e^x,sin(x)$可以展开成多项式逼近的函数作用在矩阵上都可以先特征值分解做简化。

<img src="矩阵计算/image-32.png" alt="" width="70%" height="70%">


特征值的定义
<img src="矩阵计算/image-33.png" alt="" width="70%" height="70%">

对于对称矩阵：
<img src="矩阵计算/image-34.png" alt="" width="70%" height="70%">


三个对称矩阵特征值特征向量重要的结论：
<img src="矩阵计算/image-35.png" alt="" width="70%" height="70%">
非对称矩阵在这三个结论上的说法：
<img src="矩阵计算/image-36.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-37.png" alt="" width="70%" height="70%">
挺实用的几个tips。

同时这里提到了特征值的条件数
<img src="矩阵计算/image-38.png" alt="" width="70%" height="70%">

特征值的代数重数大于几何重数
<img src="矩阵计算/image-39.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-40.png" alt="" width="70%" height="70%">


相似矩阵具有相同的特征值：
<img src="矩阵计算/image-41.png" alt="" width="70%" height="70%">

实对称矩阵一定可以对角化！

<img src="矩阵计算/image-42.png" alt="" width="70%" height="70%">

对于有重根则需要进一步去算，不一定可以，也不一定不可以。

## 数值稳定

用二范数的时候，cond就是最大奇异值和最小奇异值的比值。
所以添加对角线eps可以起到稳定作用。
<img src="矩阵计算/image-43.png" alt="" width="70%" height="70%">

条件数一些性质和应用

<img src="矩阵计算/image-44.png" alt="" width="70%" height="70%">


> **QR 分解也是从 $A$ 出发的，为啥我们只说它的条件数是 $\kappa(A)$，不是多次出现就变得更坏？**

我们来从线性代数和数值分析的角度严谨地解释这个现象。

---

### 为什么 QR 分解中不会放大条件数？

---

### 📌 一、QR 分解过程是「稳定变换」

QR 分解是：

$$
A = Q R
$$

其中：

* $Q$：正交矩阵，满足 $Q^H Q = I$，不会放大误差（旋转 + 反射操作）
* $R$：上三角矩阵，决定了解法的“病态程度”

我们把 QR 分解用来解最小二乘问题时：

$$
Ax = b \Rightarrow QRx = b \Rightarrow Rx = Q^H b
$$

现在你注意：

* $Q^H$：**正交矩阵的共轭转置**，不会放大向量（$\|Q^H b\| = \|b\|$）
* 真正解的过程是：解 $Rx = Q^H b$

所以误差传播（condition）主要看的是：

> **Rx = ...** 这个系统里，$R$ 的条件数。

而这个 $R$ 的条件数与 $A$ 是一样的（不会平方变差）：

$$
\text{cond}(A) = \text{cond}(R)
$$

所以：

> QR 分解虽然用了 $A$，但它**没有像 $A^H A$ 那样把病态放大**。

---

### 📌 二、$A^H A$ 为什么会平方放大？

再复述一下对比：

* QR 解法只做了一次操作：从 $A$ 得到 $R$
* 正规方程法做了：先转置再乘自己 $A^H A$，再求逆 —— 相当于对病态矩阵「用力过猛」，错误被放大了两次（平方）

---

### ✅ 对比总结表格：

| 方法     | 解的形式                     | 条件数级别         | 放大误差来源            |
| ------ | ------------------------ | ------------- | ----------------- |
| 正规方程法  | $x = (A^H A)^{-1} A^H b$ | $\kappa(A)^2$ | 来自 $A^H A$ 的平方放大  |
| QR 分解法 | $Rx = Q^H b$             | $\kappa(A)$   | 只与 $R$ 有关，等价于 $A$ |

---

### 🔁 回答你最初的问题：

> **QR 解法中只有一个 A，为什么？**

因为：

* QR 只是把 A 拆成 $Q$ 和 $R$，没有构造 $A^H A$ 这样的“高阶组合”
* $Q$ 是稳定的，几乎没有数值影响（单位条件数）
* 所以唯一影响解的精度的是 $R$，而 $R$ 的条件数和 $A$ 相同

## 奇异值分解

定义：
<img src="矩阵计算/image-45.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-46.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-47.png" alt="" width="70%" height="70%">
第三点很重要，提供一个新的视角。

针对第四点：

<img src="矩阵计算/image-48.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-49.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-50.png" alt="" width="70%" height="70%">


> **既然奇异值是 0，那后面的列不就“没用”了吗？U 的后 $m - r$ 列不是随便选的吗？它们凭什么说是 $A^H$ 的零空间的正交基？**

我们来一点一点拆开这个问题，最后你会发现：**这些“看起来没用的列”，恰恰是矩阵结构和零空间分析的关键。**

---

### 🌟 回顾 SVD 的形式：

对一个 $m \times n$ 的矩阵 $A$，做奇异值分解：

$$
A = U \Sigma V^H
$$

* $U \in \mathbb{C}^{m \times m}$：单位酉矩阵（列是 $A A^H$ 的特征向量）
* $V \in \mathbb{C}^{n \times n}$：单位酉矩阵（列是 $A^H A$ 的特征向量）
* $\Sigma \in \mathbb{R}^{m \times n}$：对角线是奇异值 $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$，其余为 0

假设秩为 $r$，则：

$$
\Sigma =
\begin{bmatrix}
\Sigma_r & 0 \\
0 & 0
\end{bmatrix}, \quad
\text{其中 } \Sigma_r = \text{diag}(\sigma_1, \dots, \sigma_r)
$$

---

### 🔍 你的问题聚焦在哪？

你说：

> 对角线上奇异值后面都是 0，所以乘上去就没用了，那 $U$ 的后 $m - r$ 列不就“没起作用”吗？它们能随便选吗？为什么还能说成是 $A^H$ 的零空间正交基？

---

### ✅ 正解：这些“没用”的列恰恰是 **零空间方向**

我们来揭开谜底：

### 1. 奇异值为 0 ⟹ 对应方向被映射到 0

我们可以看这个结构：

$$
A = \sum_{i=1}^r \sigma_i u_i v_i^H
$$

也就是说：

* 对于 $v_1, \dots, v_r$：会被 $A$ 映射成非零向量
* 对于 $v_{r+1}, \dots, v_n$：对应奇异值为 0，意味着

  $$
  A v_i = 0
  \Rightarrow v_i \in \text{null}(A)
  $$

所以 **$V$ 的后 $n - r$ 列就构成了 $\text{null}(A)$ 的标准正交基**


### 📌 这组列虽然“看起来没用”，但在线性代数意义上是结构的一部分：

* SVD 里 $U, V$ 是完整的正交基（单位矩阵）
* 奇异值为 0 ⟹ 对应方向落入零空间
* 即使没有贡献在乘法 $A = U \Sigma V^H$ 里，它们仍然有明确的几何/空间意义！

---

### ✅ 结论总结

| 矩阵部分        | 几何含义                    | 是否“被用到”              |
| ----------- | ----------------------- | -------------------- |
| $U_{1:r}$   | $\text{range}(A)$ 的正交基  | ✅ 被乘以奇异值             |
| $U_{r+1:m}$ | $\text{null}(A^H)$ 的正交基 | ⚠️ 没有被乘以非零奇异值，但有结构意义 |
| $V_{1:r}$   | $\text{row}(A)$ 的正交基    | ✅ 被乘以奇异值             |
| $V_{r+1:n}$ | $\text{null}(A)$ 的正交基   | ⚠️ 映射为 0，但表征了零空间     |

---

### 几何解释：

<img src="矩阵计算/image-51.png" alt="" width="70%" height="70%">


### 奇异值性质

<img src="矩阵计算/image-52.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-53.png" alt="" width="70%" height="70%">

补充左乘正交矩阵，对奇异值和特征值的影响：
<img src="矩阵计算/image-81.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-54.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-55.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-56.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-57.png" alt="" width="70%" height="70%">


相似变化有迹的不变性：（利用迹的循环不变性证明）
<img src="矩阵计算/image-59.png" alt="" width="70%" height="70%">

于是下图（2）易证：
<img src="矩阵计算/image-58.png" alt="" width="70%" height="70%">


矩阵奇异值分解例子：
<img src="矩阵计算/image-60.png" alt="" width="70%" height="70%">

## 矩阵的低秩近似
<img src="矩阵计算/image-61.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-62.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-63.png" alt="" width="70%" height="70%">
答案其实就是SVD之后前k个奇异值对应的一阶矩阵的和。（想逼近到k阶的话）
<img src="矩阵计算/image-64.png" alt="" width="70%" height="70%">


### 用处

<img src="矩阵计算/image-65.png" alt="" width="70%" height="70%">
通过奇异值分解，可以将这个评分矩阵近似为一个低秩矩阵，其中低秩矩阵的行和列分别对应于用户和商品的潜在特征。这种低秩近似能够捕捉到用户和商品之间的主要关系，去除噪声和冗余信息，从而实现更准确的推荐。


<img src="矩阵计算/image-66.png" alt="" width="70%" height="70%">


-----

## 矩阵子空间

<img src="矩阵计算/image-67.png" alt="" width="70%" height="70%">


### 四类空间关系

<img src="矩阵计算/image-68.png" alt="" width="70%" height="70%">


### 行空间 列空间 零空间

<img src="矩阵计算/image-69.png" alt="" width="70%" height="70%">



### A，B矩阵用正交Q强制对齐问题

<img src="矩阵计算/image-70.png" alt="" width="70%" height="70%">


### 投影算子
<img src="矩阵计算/image-71.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-72.png" alt="" width="70%" height="70%">


只有一部分线性算子是投影算子

<img src="矩阵计算/image-73.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-74.png" alt="" width="70%" height="70%">

投影变化为正交投影变化，当投影算子是对称时：
<img src="矩阵计算/image-75.png" alt="" width="70%" height="70%">

一个有趣小性质：
<img src="矩阵计算/image-76.png" alt="" width="70%" height="70%">


<img src="矩阵计算/image-77.png" alt="" width="70%" height="70%">

<img src="矩阵计算/image-78.png" alt="" width="70%" height="70%">


### 信号子空间与噪声子空间

<img src="矩阵计算/image-79.png" alt="" width="70%" height="70%">
<img src="矩阵计算/image-80.png" alt="" width="70%" height="70%">