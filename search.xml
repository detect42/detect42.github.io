<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/post/4a17b156.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>急雨-客栈-故事</title>
    <url>/post/cb15d88e.html</url>
    <content><![CDATA[<h2 id="center-急雨-客栈-故事-center"><center> 急雨·客栈·故事 </center></h2>
<font size=4>
<p>阴沉的天降下几粒雨点，狂风呼啸着刮过肃杀的街头，雨滴肆意飞溅的声音在街头猛地炸开。南方的雨向来是任性的也是没有征兆的。</p>
<p>一路小跑着的年轻人，匆匆踏步进入一家不起眼的客栈。</p>
<p>“这鬼天气，真是糟糕透了。”年轻人在客栈内抬头望向灰蒙蒙的天空，焦急地跺着脚。嘶拉嘶拉的雨声连绵不绝，一点也没有要停下的意思。年轻人轻叹一声，转身看向柜台前坐着的掌柜，“您好，能让我在这歇一歇脚吗，这雨——，实在是倒霉透了”。</p>
<p>掌柜是一位面善的老者，年轻时四处打拼希望出人头地不枉此生，但是到头来却觉得不如客栈安逸。“坐坐坐，不要客气。”掌柜指向离柜台最近的一张桌子，“这么突然的暴雨诶，喝酒品茶的熟人怕是不会来了，正闲得慌哩。”  年轻人的视线扫过客栈，藤椅稀错落有致地排列在厅室里，客栈不大，但是布置得几分精致，客栈无人，又让这精致萧条了几分。</p>
<p>“谢谢，不过我也没什么可以聊，相较于他人，我的人生没有波澜起伏，也没有太多的十字路口。要说故事，也许这场雨，这个客栈能算上一个。”掌柜笑了笑，“这就糟糕了，我这门口罗雀的小客栈本身也没有什么故事可谈，诶，要是平日里，可以听到旅者讲述远方的故事，或是听听当地人发发牢骚什么的。哎，你瞧，比如这位——”</p>
<p>披着泛旧的夹克，不太相符的圆顶帽，一位可以说是将如客栈外暴雨般的沧桑写在脸上的中年人轻轻推开客栈门，踱步走了进来，要了碗酒。熟练的绕过层层桌椅走到客栈里最靠窗的位子坐下，并没有说什么别的话。</p>
<p>年轻人正疑惑之时，掌柜边温酒一边继续说道：“对，就是这个人，平日里会讲一些不错的故事，你可以找他聊聊，说不定有一些不错的故事，顺便，我也可以在一旁听一听。”年轻人瞥了一眼窗外的雨，一点也没有要停的迹象，便点了点头，走到中年人对面的藤椅上坐下，“你好，听说你有许多不错的故事，我可以听一听吗？”</p>
<p>年轻人看向中年人时，中年人正凝视着窗外，中年人没有过多的表情，年轻人只能从他深邃的眼睛里看出若隐若现的忧郁。</p>
<p>“故事，哪有什么故事，我不过是一个过路人罢了。”中年人的眼神仍没有从窗外移开。</p>
<p>​       年轻人沉默了片刻，“这碗酒钱我付了，怎么样？”</p>
<p>​       中年人收回目光，端着酒碗喝上一口。</p>
<p>​       “从前，有一个悲剧人物叫<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>a</mi><mi>r</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">Earring</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span>，他——”，“停停停，这你都讲了多少遍了。”掌柜倏地凑过来打断了中年人。“咳，过去有这么个传奇人物<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>d</mi><mi>x</mi><mi>c</mi><mi>a</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>i</mi></mrow><annotation encoding="application/x-tex">idxcaicai</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault">i</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault">i</span></span></span></span>”，“这也是老故事了，那几个传奇人物的故事都大同小异，没什么意思，我说伙计，不要拿它们混新人的酒钱。”</p>
<p>​       青年人笑了笑，似乎是想说什么，但是没有发声。</p>
<p>​       中年人顿了顿，拿起酒碗猛地喝了一半，“故事虽然不多，但新的总还是有的。”说罢，闭上眼，忆了忆。</p>
<p>​       “他叫作<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">detect</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span></span></span></span>，是一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>i</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">oier</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">i</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>（信息竞赛er），哦不，曾是个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>i</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">oier</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">i</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>。”</p>
<p>​       “喂，等等，你这不会是现编的吧。”掌柜已就近搬来一张藤椅，做了下来。</p>
<p>​       “现编的又怎样，现实是现实，故事是故事，故事始于生活最后高于生活，所以故事才能比生活更有趣。” 对面的年轻人肯定地点了点头。</p>
<p>​       中年人得意的一笑，一口气将碗里剩下的酒喝完，继续讲了下去：</p>
<p>​       “最初，他只是一个在数学上不错，文化课略显蹩脚的普通初中生。在班级号召下，学习着数学竞赛。他也并不是最顶尖或是最用功的一撮。但是在一个四月，他同时取得了数学竞赛和文化课半期考试非常不错的成绩，是因为运气好，还是之前没有尽力，鬼知道呢。”</p>
<p>​       “又是这样的开局，然后呢？希望有点与众不同的东西。”掌柜大笑着打断道。</p>
<p>​       年轻人没有发言，只是安静地听着。</p>
<p>​       “这个节骨眼上的喜讯刺激着他下定决心继续数学竞赛，他的数学老师本就是当地出名的竞赛教练，他的数学竞赛征途本应就此正式展开。但是，命运这个东西，能够预测的话就不能称之命运了。不幸的是，在同一年的秋天，教育部以减压之名强制停办了大部分学科竞赛。虽然被迫告别了数学竞赛，但是他的热情已经被点燃，秉着对计算机的主观上的兴趣和客观上经教育部减压后幸存的信息竞赛，他选择了试试信息竞赛，彼时的他还不知道日后等待着他的会是什么。“</p>
<p>​       中年人顿了顿，吸上一口气调整语调。</p>
<p>​       “经过一学期课余时间的努力，他得到了暑假与高中生一起集训的机会，他以高中竞赛生为目标，没日没夜的追赶着。逐渐，他忘记了最初资质平平的自己，开始接收其他强者的拥抱。白驹过隙般，初中时光就这么走过，他收获了一个二等一个一等，哦，还有一个相对不错足以让他去有着信息竞赛传统的高中的中考成绩。”</p>
<p>​       “他的高中的竞赛体系算比较完备，意味着他有了选择停上文化课全力冲刺竞赛的机会，他看着优秀学长们的一块块总决赛奖牌发愣，有朝一日，这也会是他的命运吗？不过除了难懂的竞赛知识，还有一件让他费解的事，周围起初在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>i</mi></mrow><annotation encoding="application/x-tex">oi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">i</span></span></span></span>（信息竞赛）上展露天赋的同学，却一个个选择了退出。在他还没意识到的时候，愿意停课冲刺竞赛的人已然越来越少了。另外值得一提的是一个周末，同学突然遗憾地对他说：</p>
<p>‘<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">detect</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span></span></span></span>，我可能学不了多久了。’</p>
<p>‘为什么？’</p>
<p>‘我父母还是担心我的文化课成绩，不再支持我继续学下去，我文化课成绩本就不好，也说不过他们。你父母支持你真是幸运。’</p>
<p>忘了说，这位同学叫<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>s</mi><mtext>君</mtext></mrow><annotation encoding="application/x-tex">Rs君</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">s</span><span class="mord cjk_fallback">君</span></span></span></span>，和他一样的人不少。这也不禁让他思考起来，回报和风险，幸运与遗憾总是同时存在。”</p>
<p>“然后呢，他有选择取舍吗？”年轻人似乎被吊起了兴致，开始主动发问。</p>
<p>“多少个夜晚，他独自在偌大却空无一人的操场上踱步，不远处教学楼灯火通明，他的高中同学们此时正上着文化课晚自习，他时而叹气，时而握紧拳头，路过不那么亮的路灯，路过球场，路过单杠，他就这么走啊走，在心里小心翼翼地评估着未来。他会觉得选择了的事不能止于半道，也会突然感觉如履薄冰徒留迷惘。”</p>
<p>中年人说话的间隙，掌柜已然重温了一碗酒，中年人顺手接下。</p>
<p>“一定到高潮了吧” 掌柜有感而问。</p>
<p>中年人笑笑，没有回答。</p>
<p>“他最后还是坐回了曾让他心驰神往的机房，至于原因，谁知道呢。知道的只是从此他的轴迹便和普通高中生彻底分叉开来，没有了周考月考、晚自习、甚至日常课表，取而代之的则是竞赛培训和日复一日的模拟考。令他记忆犹新的是，钟老师操着厚重北方口音，配着抽象的课件，让他明白什么是听不清、看不明、学不懂、以及认真听课的他是多么的愚蠢。他认识到自己的程序时间常数总是莫名其妙地比别人大（雾），并在日后的大大小小比赛中得到有效实践（悲）。”</p>
<p>“当然，信息竞赛也不乏有趣的事。起初，或是因为腼腆或是相互推让，大家都不愿意主动讲题，可是一旦教练宣布讲题奖励奶茶政策后，大家又抢得不可开交。平日里霸榜<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>a</mi><mi>n</mi><mi>k</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">rank1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord">1</span></span></span></span>的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>s</mi><mi>y</mi><mi>o</mi></mrow><annotation encoding="application/x-tex">fsyo</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">s</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">o</span></span></span></span>乐此不疲地讲着水题，腼腆的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>s</mi><mi>s</mi><mi>s</mi><mi>t</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">wssstc</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">c</span></span></span></span>总是小声嘀咕着奇奇怪怪的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>j</mi></mrow><annotation encoding="application/x-tex">loj</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>题，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>m</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">pmh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">m</span><span class="mord mathdefault">h</span></span></span></span>仍维持着高冷的形象，只言片语便讲完一道<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>F</mi></mrow><annotation encoding="application/x-tex">CF</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span></span></span></span>神题。”他沉浸在这样的时光里，每晚压着十点半点校门关闭背着电脑离开学校。他经历了许多，学习新知识的激动，模拟考翻车的遗憾，讲题后收获掌声的喜悦骄傲，以及被考题暴打的无力感。那一年的联赛，虽然他考得烂透了，但他没有抱怨，仍感谢上苍能继续学下去，毕竟机会还未泯灭。”</p>
<p>“时间过得很快，转眼到了高二的寒假，他的联赛成绩虽然不够理想但是足以让他入围省队选拔，只要进了省队，离他梦想中的奖牌便只是一步之遥。”</p>
<p>“你这么说，不会这个时候出了什么事吧。”掌柜问道。</p>
<p>“谁也想不到是，他在的省的传统省选被取消了，取而代之的选拔方式则是题目数量少而怪的冬令营题目，意味着所有人被卷入一场完全不可预知的博弈。”</p>
<p>“是他的省出什么事了吗？”年轻人紧跟着发问。</p>
<p>“无可奉告”</p>
<p>“那他的省选怎么样了”</p>
<p>“你问得太快了。”掌柜对年轻人说。年轻人将抬起的手缓缓放下，“抱歉，请继续吧”。</p>
<p>“他倒是没有过多的不安，自他选择信息竞赛的一刻起，已经做好了最坏的打算。’已经没什么好害怕的了‘他常常这么安慰自己。”</p>
<p>“最后的冬令营考试前，他唯一期望的是最后能安心看着挂着的钟摆结束考试。但是命运并没有给他这个廉价的礼物。他在最后十五分钟猛地发现第一题算法假掉了，慌忙中的补救并没有奏效，这十五分钟可悲地成了他<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>I</mi></mrow><annotation encoding="application/x-tex">OI</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span>生涯的倒计时。”</p>
<p>“故事就这么结束了？他就这么退役了？”年轻人显得不可置信。</p>
<p>中年人重新看向窗外，密密麻麻的雨点开始变得稀疏，雨点打在水坑上的涟漪已然清晰可见。中年人又抿了一口酒缓缓地说：“是啊，退役了。”</p>
<p>掌柜缓缓站了起来，“这种人我听得多了也见的多了，不是所有的努力与梦想都有回报，如果你代入他们或许或觉得感伤，但是见得多了，也就不觉得了。医院里有人不幸过世时，年轻的实习者往往会和家属一起落泪，但是经验丰富的医生往往只会微叹一口气。道理是一样的。况且在追求高远目标的途中默默陨落也没什么好同情的，毕竟任何成功和奇迹都是有代价的，而代价早该在出发前就想清楚。不过，伙计，你这故事还是不错的，对得起新人的酒钱。这会儿雨要停了，我得准备接客了，把钱放柜台上就行。”掌柜离开了藤椅。</p>
<p>中年人急着道：“你看故事还没讲完呢，后来他重头学习高中文化课，很快和班级打成一片，下棋乒乓球也不错”。</p>
<p>但是掌柜已然走开了。</p>
<p>噼噼啪啪的雨声消失了，路上行人的身影又多了起来，天空似乎都了亮了些。一缕阳光穿透云层的空隙射进客栈窗户，只听得见雨滴从屋檐规律落下的滴答声。</p>
<p>“我走晚点没有关系，接下来呢？”年轻人忽的说道。</p>
<p>中年人把目光拉了回来，眼角渐渐放松，用着一种柔和的目光看向年轻人。“很少见到对这个故事如此感兴趣的人，不过记住，这也不过是我道听途说的故事罢了，无论有多么吸引人，不要总是听信他人的故事，属于你的选择始终在当下。”</p>
<p>“我当然会选择当下，一路我都是这么过来的，您能继续了吗？”</p>
<p>“后来啊，他很快融入了班级，和正常的高中生一样参加了高考，但冗杂且繁多的文化课并没有给他留下太多印象，他选择记住了同学聚餐，一个个玩笑，以及晚自习溜去打球的紧张与兴奋。”</p>
<p>阴云已然散去，几洼浅浅的积水倒映着明亮的天空，雨后的客栈显得更加朴素而又柔和。</p>
<p>“当然，他的故事并没有结束，他考上了南京大学，再后来……”<br>
<font size=4></p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>git初步</title>
    <url>/post/91c7c6a1.html</url>
    <content><![CDATA[<h1 id="git基本命令">git基本命令</h1>
<h2 id="git详细介绍-使用">git详细介绍&amp;使用</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/896043488029600">史上最浅显易懂的Git教程</a></p>
<h2 id="git指令简版总结">git指令简版总结</h2>


	<div class="row">
    <embed src="https://liaoxuefeng.gitee.io/resource.liaoxuefeng.com/git/git-cheat-sheet.pdf" width="100%" height="550" type="application/pdf">
	</div>


]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo食用技巧</title>
    <url>/post/b1320771.html</url>
    <content><![CDATA[<h1 id="关于hexo的合理食用">关于hexo的合理食用</h1>
<h2 id="1-添加pdf">1. 添加pdf</h2>
<ol>
<li>\post\pdf本地目录下本地加入xxx.pdf</li>
<li>md文件里加入</li>
<li>也可以直接插入网址外部访问</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">&#123;% pdf pdf/xxx.pdf %&#125;</span><br></pre></td></tr></table></figure>
<h2 id="插入图片">插入图片</h2>
<p>将图片保存在\post下，直接调用即可，可以改变图片长宽比例以及大小</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">&lt;img src=<span class="string">&quot;xxx.png&quot;</span> width=<span class="string">&quot;10%&quot;</span> height=<span class="string">&quot;10%&quot;</span>&gt;</span><br></pre></td></tr></table></figure>
<img src="1.png" width="10%" height="10%">]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>tips for vim</title>
    <url>/post/54b5cdaf.html</url>
    <content><![CDATA[<h1 id="一些tips">一些tips</h1>
<p>可以在settings里面自定义vim映射</p>


	<div class="row">
    <embed src="pdf/vim.pdf" width="100%" height="550" type="application/pdf">
	</div>



]]></content>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>effctive c++ tips</title>
    <url>/post/a20e8ec8.html</url>
    <content><![CDATA[<h2 id="1-除非有好的理由允许构造函数隐式转换-否则申明构造函数为explicit">1. 除非有好的理由允许构造函数隐式转换，否则申明构造函数为explicit</h2>
<hr>
<h2 id="2-default构造函数-copy构造函数-copy-assignment操作符">2. default构造函数，copy构造函数，copy assignment操作符</h2>
<p>新对象被定义一定有个构造函数被调用</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Class w1;<span class="comment">//default </span></span><br><span class="line"><span class="function">Class <span class="title">w2</span><span class="params">(w1)</span></span>;<span class="comment">//copy构造</span></span><br><span class="line">Class w1=w1;<span class="comment">//copy赋值操作符</span></span><br><span class="line">Class w3=w2;<span class="comment">//copy构造</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="3-类中声明常量">3. 类中声明常量</h2>
<p>为确保此常量只有一个实例，用static</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span>&#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">const</span> <span class="type">int</span> Num=<span class="number">5</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时也可以使用enum</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span>&#123;</span><br><span class="line">    <span class="keyword">enum</span>&#123;Num=<span class="number">5</span>&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>enum特征：</p>
<ol>
<li>enum和define一样不允许指针指向自己，绝不会导致不必要的内存分配</li>
<li>实用主义，很多代码用了它</li>
</ol>
<hr>
<h2 id="4-const食用技巧">4. const食用技巧</h2>
<ul>
<li>
<h3 id="1-const对象只能调用const成员函数-不能调用非const成员函数；非const对象可以调用const成员函数">1. const对象只能调用const成员函数、不能调用非const成员函数；非const对象可以调用const成员函数</h3>
</li>
</ul>
<h3 id="引发原因：-由调用成员函数时隐式传入的当前对象的this指针引起">引发原因： 由调用成员函数时隐式传入的当前对象的this指针引起。</h3>
<blockquote>
<p>1、 非<code>const</code>成员函数中的隐式参数：classA* this</p>
</blockquote>
<blockquote>
<p>2、 <code>const</code>成员函数中的隐式参数：<code>const classA* this</code></p>
</blockquote>
<h3 id="根本原因：">根本原因：</h3>
<blockquote>
<p>1、 <code>const</code>对象的指针为<code>const classA* this</code>，因此传入非const成员函数时编译器报错（类型不匹配，无法从const 指针转换为非const指针）；但传入const成员函数则类型匹配。</p>
</blockquote>
<blockquote>
<p>2、非<code>const</code>对象的指针为<code>classA* this</code>，可以调用const成员函数，因为const修饰符保证了不会修改该对象。</p>
</blockquote>
<p>所以对于const对象可能调用的函数，可以直接加个const函数重载，c++支持const函数重载。</p>
<ul>
<li>
<h3 id="2-类中使用mutable定义-这样在const成员函数中可以修改其值">2. 类中使用mutable定义，这样在const成员函数中可以修改其值</h3>
</li>
<li>
<h3 id="3-const类不能作为按地址形式传入non-const函数中">3. const类不能作为按地址形式传入non-const函数中</h3>
</li>
<li>
<h3 id="4-对operator-使用const-防止如a-b-c的意外引用">4. 对operator * 使用const，防止如<code>a*b=c</code>的意外引用</h3>
</li>
</ul>
<hr>
<h2 id="5-make-sure-that-objects-are-initialzed-before-they-re-used">5. Make sure that objects are initialzed before they’re used</h2>
<blockquote>
<p>建议永远使用<code>member initialization list</code>。（就算没有任何额外赋值，也建议在初始化成员列表里手动调用default或对内置数据类型附初值）</p>
</blockquote>
<blockquote>
<p>实际上，构造函数在运行前会对所有类成员调用default构造一遍，这样花费了不必要的时间开销。况且，如const常量一定需要初始值，而不能被赋值。</p>
</blockquote>
<hr>
<h2 id="6-构造-析构-赋值运算">6. 构造/析构/赋值运算</h2>
<ul>
<li>
<h3 id="1-只要你写了一个构造函数-default版构造函数就不会创建">1. 只要你写了一个构造函数，default版构造函数就不会创建</h3>
</li>
<li>
<h3 id="2-当类中有const成员-引用成员-string-或者base-class的赋值操作符是private-那么编译器拒绝生成默认operator">2. 当类中有const成员，引用成员(string&amp;),或者base class的赋值操作符是private，那么编译器拒绝生成默认operator=。</h3>
</li>
<li>
<h3 id="3-不想编译器自动生成函数-可以-delete">3. 不想编译器自动生成函数，可以<code>=delete</code></h3>
</li>
<li>
<h3 id="4-心得：只有当class内至少含有一个virtual函数-才为它声明virtual析构函数-virtual函数会开一个虚函数表占用内存-同时因为stl标准库里全是non-virtual-所以一般不将其作为base-class继承">4. 心得：只有当class内至少含有一个virtual函数，才为它声明virtual析构函数（virtual函数会开一个虚函数表占用内存）,同时因为STL标准库里全是non-virtual，所以一般不将其作为base class继承。</h3>
</li>
<li>
<h3 id="5-在虚析构函数继承时需要对虚析构函数提供实现">5. 在虚析构函数继承时需要对虚析构函数提供实现.</h3>
</li>
</ul>
<blockquote>
<p>因为当我们不定义虚构函数的时候，编译器会默认生成一个什么都不做的析构函数，但是注意了默认生成的析构函数就是普通函数不是虚函数！！！（因为虚函数会带来额外开销，c++追求的是速度），所以指望不上编译器自动生成虚构函数，而析构时又一定会调用，所以需要我们手动实现虚析构函数的实现。</p>
</blockquote>
<hr>
<h2 id="7-在构造函数和析构函数间不调用virtual函数">7.在构造函数和析构函数间不调用virtual函数。</h2>
<blockquote>
<p>因为这类调用从不下降至derived class。（需要的话可以用static函数从derived class传参向base class的构造函数，并在base里用non-virtual函数接收并按照接收参数的不同做出不同response。</p>
</blockquote>
<hr>
<h2 id="8-让operator-返回一个reference-to-this">8. 让operator=返回一个reference to *this</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Widget&amp; <span class="keyword">operator</span> =(<span class="type">const</span> Widget&amp; rhs)&#123;</span><br><span class="line">    <span class="comment">//******</span></span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一方面可以实现连等，另一方面这样的协议被STL共同遵守。</p>
<hr>
<h2 id="9-以对象为资源管理-rall-resource-acquisition-is-initializaion">9. 以对象为资源管理(RALL(resource acquisition is initializaion))</h2>
<ul>
<li>
<h3 id="1-获得资源后立刻放进管理对象-如使用auto-ptr">1. 获得资源后立刻放进管理对象（如使用auto_ptr）</h3>
</li>
<li>
<h3 id="2-管理对象-managing-object-运用析构函数确保资源被释放">2. 管理对象(managing object)运用析构函数确保资源被释放</h3>
</li>
</ul>
<p>以防止开的空间在delete前因各种原因中端而导致内存泄漏<br>
auto_ptr一般用在heap_based资源</p>
<hr>
<h2 id="10-rall对象的copy行为">10. RALL对象的copy行为</h2>
<ul>
<li>
<h3 id="1-方法1：抑制copying-用private写copy">1. 方法1：抑制copying（用private写copy）</h3>
</li>
<li>
<h3 id="2-方法2：施行引用计数法-tr1-shared-ptr-可以以一个函数对象为第二参数-在计数为0时调用其">2. 方法2：施行引用计数法(tr1::shared_ptr,可以以一个函数对象为第二参数，在计数为0时调用其)</h3>
</li>
</ul>
<hr>
<h2 id="11-资源管理类中提供对原始资源的访问">11. 资源管理类中提供对原始资源的访问</h2>
<p>我们用RALL类将对象装在类中防止内存泄漏发生，但是一些api要求原始的数据进行传参，这时就需要提供对原始资源的访问</p>
<blockquote>
<p>对于智能指针<code>pINv.get()</code>即可调用其储存的原始资源</p>
</blockquote>
<blockquote>
<p>对于其他某些RALL类要么提供显式转换函数(如上)，要么提供隐式转换函数(<code>operator type()</code>)</p>
</blockquote>
<hr>
<h2 id="12-成对使用new和delete时要采用相同的形式">12. 成对使用new和delete时要采用相同的形式</h2>
<hr>
<h2 id="13-以独立语句将newed对象置于智能指针中">13. 以独立语句将newed对象置于智能指针中</h2>
<blockquote>
<p>这样在new对象创立到将对象存进RALL中没有其他语句干扰，防止难以察觉的资源泄露（可能其他语句会中断，导致只创立了new对象没放到RALL类里面）</p>
</blockquote>
<hr>
<h2 id="14-让接口更容易被使用">14. 让接口更容易被使用</h2>
<blockquote>
<ul>
<li>接口的一致性，与内置类型的行为兼容</li>
<li>“阻止误用”的办法包括建立新类型、限制类型上的操作、束缚对象值，以及消除客户的资源管理责任。</li>
<li><code>c++ tr1::shared_ptr</code>支持定制型删除器。</li>
</ul>
</blockquote>
<hr>
<h2 id="15-类型转化">15. 类型转化</h2>
<blockquote>
<pre><code>       T1 ---&gt; T2
</code></pre>
<ul>
<li>在T1中写一个类型转换函数（operator T2）???</li>
<li>或在T2中写一个non-explicit-one-aegument的构造函数</li>
</ul>
</blockquote>
<hr>
<h2 id="16-尽可能用pass-by-reference-to-const替换pass-by-value">16. 尽可能用pass-by-reference-to-const替换pass-by-value</h2>
<blockquote>
<p>第一，效率更好。第二，解决继承时的切割(slicing)问题<br>
以上规则不适用于内置数据类型和STL</p>
</blockquote>
<hr>
<h2 id="17-返回值reference和object之间的抉择">17. 返回值reference和object之间的抉择</h2>
<blockquote>
<p>绝不要返回pointer或reference指向一个local stack对象，或返回reference指向一个local-allocated对象。</p>
</blockquote>
<hr>
<h2 id="18-将成员变量设计为private">18. 将成员变量设计为private</h2>
<blockquote>
<p>切记将成员变量设计成private，好处：1. 访问数据的一致性 2. 可以细微划分访问时的控制权限 3. 提供class作者充分的实现弹性。</p>
</blockquote>
<blockquote>
<p>protected 并不比public 更具备封装性</p>
</blockquote>
<hr>
<h2 id="19-prefer拿non-member-non-friend函数替换member函数">19. prefer拿non-member non-friend函数替换member函数。</h2>
<p>可以增加封装性，包裹弹性，和机能拓展性。</p>
<blockquote>
<p>越少的函数能直接调用私有数据，封装性越好</p>
</blockquote>
<blockquote>
<p>将多个功能函数（如clear功能、cookie功能）放在多个头文件但隶属于同一个命名空间，可以轻松拓展这些功能函数。（namespace可以跨越多个源码文件）</p>
</blockquote>
<hr>
<h2 id="20-non-member函数">20. non-member函数</h2>
<p>如果你需要为某个函数的所有参数（包括被this指针所指的那个隐喻参数）进行类型转换，那么这个函数必须是non-member。</p>
<p>最常见的是operator重载运算，因为this指针无法进行隐式类型转换，所以有必要变成non-member函数。但是是不是要friend是不一定的。不能只因函数不该是member，就让它自动成为friend。</p>
<hr>
<h2 id="21-swap的实现">21. swap的实现</h2>
<ul>
<li>当std::swap对你的类型效率不高时，提供一个swap成员函数，并确定这个函数不抛出异常。</li>
<li>如果你提供一个member swap，也提供一个non-member swap用来调用前者。对于classes（而非templates），也要特化std::swap&gt;</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Widget</span>&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(Widget&amp; other)</span></span>&#123;</span><br><span class="line">        <span class="keyword">using</span> std::swap;</span><br><span class="line">        <span class="built_in">swap</span>(Ptr,other.Ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">namespace</span> std&#123;</span><br><span class="line">    <span class="keyword">template</span>&lt;&gt;</span><br><span class="line">    <span class="type">void</span> <span class="built_in">swap</span>&lt;Widget&gt;(Widget&amp; a,Widget&amp; b)&#123;</span><br><span class="line">        a.<span class="built_in">swap</span>(b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>调用swap时加上using std::swap，然后调用的时候不带任何“命名空间资格修饰”。</p>
</li>
<li>
<p>swap调用顺序： 1：class专属的swap 2：std::swap内的专属特化版 3：默认版std::swap。</p>
</li>
</ul>
<hr>
<h2 id="22-尽可能延后变量定义式的出现时间">22. 尽可能延后变量定义式的出现时间</h2>
<p>不只因该延后到非得使用该变量为止，甚至应该尝试延后这份定义知道能够给它初值实参为止。</p>
<p>不仅可以避免构造非必要对象，还可以避免无意义的default构造行为，更深一层说，以“具有明显意义之初值”将变量初始化还可以附带说明变量的目的。</p>
<hr>
<h2 id="23-c-转型操作">23. c++转型操作</h2>
<ul>
<li>
<h3 id="宁可用c-style转型-不使用旧式转型-前者很容易被分辨出来-而且作用更加细化">宁可用c++style转型，不使用旧式转型，前者很容易被分辨出来，而且作用更加细化</h3>
</li>
</ul>
<blockquote>
<p>const_cast 用来将对象的常量性移除</p>
<p>dynamic_cast 用来“安全向下转型”，也就是用来决定某对象是否归属继承体系中的<br>
某个类型。</p>
<p>reinterpret_cast 低级转型，e.g. 将pointer to int转为int</p>
<p>static_cast 强迫隐式转型</p>
</blockquote>
<ul>
<li>
<h3 id="使用旧式转型的唯一时机：调用一个explicit构造函数将一个对象传递给一个函数时">使用旧式转型的唯一时机：调用一个explicit构造函数将一个对象传递给一个函数时。</h3>
</li>
<li>
<h3 id="单个对象-如一个derived类-可以拥有一个以上的地址-所以不要以为-转型什么都没做-只是告诉编译器把某种类型视为另一种类型">单个对象（如一个derived类）可以拥有一个以上的地址，所以不要以为“转型什么都没做，只是告诉编译器把某种类型视为另一种类型“）</h3>
</li>
<li>
<h3 id="如果可以-尽量避免转型-如指针动态链接-或virtual函数">如果可以，尽量避免转型。（如指针动态链接，或virtual函数）</h3>
</li>
</ul>
<hr>
<h2 id="24-避免返回handles-reference-指针-迭代器-指向对象内部成分">24. 避免返回handles(reference,指针，迭代器)指向对象内部成分</h2>
<ul>
<li>可增加封装性，帮助const成员函数行为像一个const。</li>
<li>降低出现“虚吊号牌”(dangling handles)的可能性。（对象先寄了，导致成员赋值的内部指针虚吊。）</li>
</ul>
<hr>
<h2 id="25-关于inline">25. 关于inline</h2>
<ul>
<li>好处，调用其不用承受函数的额外开支</li>
<li>inline将“对此函数的每一个调用”都一函数本体来替换之。但是，可能会造成代码膨胀，降低高速缓存的集中率。</li>
<li>注意：将函数定义在class定义式中会隐式变成inline</li>
<li>virtual和inline不兼容，因为virtual意味着等待，运行阶段才能确定。而inline意味着执行前替换。</li>
<li>构造和析构函数往往不适合inline，哪怕是空的构造函数，编译器也会产生一定分量的代码，这样的inline往往会使代买膨胀。</li>
<li>inline内容一旦改，意味着所有用到f的内容都要重新编译，如果不用inline，重新链接即可。</li>
<li>将大多数inline限制在小型的，被频繁调用的函数身上。</li>
</ul>
<hr>
<h2 id="26-减小声明式的依赖性">26.减小声明式的依赖性</h2>
<ul>
<li>
<p>能使用object reference或者object pointer，就不要使用object。（因为如果定义某类型的object，会需要其定义式。</p>
</li>
<li>
<p>如果可以，尽量以class声明式替换class的定义式。</p>
<blockquote>
<p>注意，当你声明一个函数而用到某个class时，你并不需要其class的定义式，即使该函数以by value方式传递该class的参数(或者返回值)。</p>
</blockquote>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">date</span>;</span><br><span class="line"><span class="function">date <span class="title">Today</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ClearAppointments</span><span class="params">(date d)</span></span>;</span><br><span class="line"><span class="comment">//合法的</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="27-public继承塑模出is-a关系">27. public继承塑模出is-a关系</h2>
<p>适用于base的每一件事也一定适用于derived身上，因为每一个derived也是一个base。</p>
<p>e.g. bird类里fly函数。但是Penguin is a bird，但是不会fly。所以bird类里不能放fly函数。</p>
<hr>
<h2 id="28-避免遮盖继承而来的名称">28. 避免遮盖继承而来的名称</h2>
<ul>
<li>
<p>derived class内的名称会遮盖base class内的名称。在public继承下从来没有人希望如此。</p>
</li>
<li>
<p>为了让被遮盖的名称重见天日，可以使用<code>using声明式</code>或者<code>转交函数(forwarding function)</code>。</p>
</li>
</ul>
<hr>
<h2 id="29-接口继承与实现继承">29. 接口继承与实现继承</h2>
<ul>
<li>对于base class为真的任何事一定对其derived class也为真。因此每个函数可以用于class上，也一定可以用于derived class上。</li>
<li>声明一个pure virtual函数的目的是为了让derived classes只继承函数接口。（不干涉derived怎么实现它）</li>
<li>声明impure derived函数的目的，是让derived class继承该函数的接口和<strong>缺省实现</strong>。（default版直接用域名解析调用）</li>
<li>pure virtual函数也可以被实现，用来当缺省实现。</li>
<li>non-virtual 函数的目的是为了令derived class继承函数的接口及一份强制性的实现。</li>
</ul>
<h2 id="30-考虑用设计模式替换virtual函数">30. 考虑用设计模式替换virtual函数</h2>
<p>介绍两种设计模式，NVI(non-virtial interface)，主张将所有virtual设计为private。Strategy设计模式，用函数指针或者古典strategy，另外开个类。</p>
<p>因为是关于设计模式的介绍，详细可以看他人的 <strong><a href="https://blog.csdn.net/CltCj/article/details/128432338">博客分享</a></strong>。</p>
<hr>
<h2 id="31-绝不重新定义继承而来的non-virtual函数">31. 绝不重新定义继承而来的non-virtual函数</h2>
<ul>
<li>
<p>non-virtual函数为静态绑定，也就是说pointer-to-base永远调用的是base版本，即使其指向一个derived类。一个简单的例子是为什么多态中析构函数都是virtual：虚析构函数为了避免内存泄露,基类的析构函数一般都是虚函数。 如果基类析构函数不是虚函数:基类指针指向子类对象,delete基类指针,调用基类析构函数,不会调用子类析构函数,造成内存泄露。</p>
</li>
<li>
<p>non-virtual函数的不变性高于其特异性。（public继承下，一切base的non-virtual都适用于所有的derived classes）</p>
</li>
</ul>
<hr>
<h2 id="32-绝不重新定义继承而来的缺省参数值">32. 绝不重新定义继承而来的缺省参数值</h2>
<p>理由很简单，virtual函数时动态绑定(dynamically bound)，而缺省参数值却是静态绑定。</p>
<p>所以如果使用多态时，重新定义了继承而来的缺省参数值，在动态绑定中，其默认参数却永远是base的，导致难以发现的错位。（继承中唯一该覆写的东西是virtual函数）</p>
<p>（如果想要统一默认参数，可以使用30条中的NVI设计模式。）</p>
<hr>
<h2 id="33-复合关系">33. 复合关系</h2>
<ul>
<li>在应用域(application domain)，复合意味着has-a。</li>
<li>在实现域(implementation domain)，复合意味着 is-implemented-in-terms-of（根据某物实现出）。e.g. 用std::list 实现SET。</li>
</ul>
<hr>
<h2 id="34-private继承">34. private继承</h2>
<p>public继承在必要时可（为了让函数调用成功），可以将derived类转成base，而private继承则不行。</p>
<p>private base 继承而来的所有东西都会在derived类中变成private属性。</p>
<ul>
<li><strong>private继承意味着只有实现部分被继承，接口部分应略去。如果D以private形式继承B，意思是D对象根据B对象实现而得，再没有其他意涵了。</strong></li>
</ul>
<p>复合(composition)比private继承 （都是is-implemented-in-terms-of）</p>
<ul>
<li>复合优点：阻止derived类重新定义接口、可以解耦</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Widget</span>&#123;</span><br><span class="line">    <span class="keyword">private</span>: </span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">WidgetTimer</span>: <span class="keyword">public</span> Timer&#123;</span><br><span class="line">        <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">onTick</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">        <span class="comment">//...</span></span><br><span class="line">    &#125;;</span><br><span class="line">    WidgetTimer timer;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li>private继承优点：当derived函数需要访问protected based class的成员、或需要重新定义继承而来的virtual函数。</li>
</ul>
<hr>
<h2 id="35-多重继承">35. 多重继承</h2>
<ul>
<li>多重继承比单一继承更复杂。它可能导致新的歧义性，以及对virtual继承的需要。</li>
<li>virtual继承会增加大小，速度，初始化复杂度成本。</li>
<li>多重继承的确有正当用途。比如：<code>&quot;public继承某个inteface class&quot;,&quot;private继承某个协助实现的class&quot;</code>的两两组合。</li>
</ul>
<hr>
<h2 id="36-隐式接口和编译器多态">36.隐式接口和编译器多态</h2>
<ul>
<li>class和template都支持接口和多态</li>
<li>对class而言接口是显示的，以函数签名为中心。多态则是通过virtual函数发生于运行期。</li>
<li>对template参数而言，接口是隐式的，奠基于有效表达式。多态则是通过template具现化和函数重载解析发生于编译期。</li>
</ul>
]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>python入门</title>
    <url>/post/15af28d0.html</url>
    <content><![CDATA[<h2 id="博客教程"><a href="https://www.liaoxuefeng.com/wiki/1016959663602400">博客教程</a></h2>
<p>讲的比较细致也比较全面，适合新手入门。</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式</title>
    <url>/post/2f57a694.html</url>
    <content><![CDATA[<h2 id="正则表达式入门"><a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017639890281664">正则表达式入门</a></h2>
<p>视觉上反人类但是好用的tool。</p>
]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>概率与期望入门</title>
    <url>/post/5572c508.html</url>
    <content><![CDATA[<h2 id="期望">期望</h2>
<h3 id="性质1：期望的线性关系">性质1：期望的线性关系</h3>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>X</mi><mo>+</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mi>E</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(X+Y)=E(X)+E(Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span></span></span></span></p>
<p>期望的可加性永远适用，即使<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">X,Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>并非独立。</p>
<h2 id="样本期望均值的期望">样本期望均值的期望</h2>
<p>与总期望一致。</p>
<h2 id="期望的乘积关系">期望的乘积关系</h2>
<ul>
<li>对于独立随机变量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>X</mi><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>E</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(XY)=E(X)*E(Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span></span></span></span></li>
</ul>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mi>X</mi><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(x)=\sum_{i=1}^m Xf(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>Y</mi><mi>g</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(y)=\sum_{j=1}^nYg(Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.24011em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>E</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(X)*E(Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span></span></span></span>拆出来就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub><msub><mi>Y</mi><mn>1</mn></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>Y</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X_1Y_1f(X_1)g(Y_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，因为变量独立，所欲等于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><msub><mi>Y</mi><mn>1</mn></msub><mo>∗</mo><mi>h</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><msub><mi>Y</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(X_1Y_1*h(X_1Y_1))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>X</mi><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(XY)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span></span></span></span>。</p>
<h2 id="方差">方差</h2>
<h3 id="定义式">定义式</h3>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo>∑</mo><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Var(x)=\sum(x-\mu)^2f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></p>
<h3 id="等价式">等价式</h3>
<ol>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>μ</mi><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Var(x)=E((x-\mu)^2),\mu=E(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">μ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>−</mo><mi>E</mi><mo stretchy="false">(</mo><mi>x</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">Var(x)=E(x^2)-E(x)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></p>
</li>
</ol>
<img src="2.png" width="60%" height="60%">
<h3 id="独立随机变量的可加性">独立随机变量的可加性</h3>
<p>对于独立随机变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1,x_2,\dots x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo>⋯</mo><mo>+</mo><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Var(x_1+x_2+\dots x_n)=Var(x_1)+Var(x_2)+\dots +Var(x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<hr>
<h3 id="条件独立和独立不是等价的概念">条件独立和独立不是等价的概念。</h3>
<hr>
<h2 id="协方差与独立性">协方差与独立性</h2>
<p>协方差的定义是从数字的表示特征出发进行概况的而随机变量独立性的定义更触及本质一些，即：X的取值不会影响Y的条件分布，因此独立性的描述意义要更强。</p>
<img src="3.png" width="60%" height="60%">
<hr>
]]></content>
      <tags>
        <tag>机器学习 概率统计</tag>
      </tags>
  </entry>
  <entry>
    <title>Python之散装知识</title>
    <url>/post/d9e0de5e.html</url>
    <content><![CDATA[<h2 id="1-staticmethod-的使用">1. @staticmethod 的使用</h2>
<p>在Python中，<code>@staticmethod</code>是一个装饰器（decorator），用于定义类中的静态方法（staticmethods）。静态方法是类中的一种方法，它与类的实例无关，因此不需要通过类的实例进行调用，而是直接通过类名调用。</p>
<p>使用<code>@staticmethod</code>装饰器可以将一个普通的方法转换为静态方法。在定义静态方法时，需要在方法上方加上<code>@staticmethod</code>装饰器。静态方法的定义和使用有以下特点：</p>
<ol>
<li>
<p><strong>不需要访问类的实例</strong>：静态方法没有 <code>self</code> 参数，因此在方法体内无法直接访问类的实例属性或调用实例方法。它只能访问类级别的属性和其他静态方法。</p>
</li>
<li>
<p><strong>通过类名调用</strong>：由于静态方法与类的实例无关，所以可以直接通过类名调用。不需要实例化类对象即可使用静态方法。</p>
</li>
<li>
<p><strong>不需要隐式传递参数</strong>：普通的实例方法会自动接收类的实例作为第一个参数，通常命名为 <code>self</code>，而静态方法没有这样的隐式传递参数，所以它在方法定义时不需要 <code>self</code> 参数。</p>
</li>
<li>
<p><strong>不能访问实例属性</strong>：由于静态方法与类的实例无关，它不能访问实例属性或实例方法。</p>
</li>
</ol>
<p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span>:</span><br><span class="line">    class_variable = <span class="number">10</span>  <span class="comment"># 类级别的属性</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x</span>):</span><br><span class="line">        self.x = x  <span class="comment"># 实例属性</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">static_method</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;This is a static method.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用静态方法，不需要实例化类对象</span></span><br><span class="line">MyClass.static_method()  <span class="comment"># Output: This is a static method.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建类的实例</span></span><br><span class="line">obj = MyClass(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 静态方法仍然可以通过类名调用</span></span><br><span class="line">obj.static_method()  <span class="comment"># Output: This is a static method.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 静态方法不能访问实例属性</span></span><br><span class="line"><span class="built_in">print</span>(obj.x)  <span class="comment"># Output: 5</span></span><br></pre></td></tr></table></figure>
<p>总结：<code>@staticmethod</code>装饰器用于定义静态方法，它可以通过类名直接调用，不需要实例化类对象，且在方法体内不能访问实例属性。静态方法在类的实例无关的情况下使用，常用于实现与类相关的工具函数或辅助函数。</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>引用</title>
    <url>/post/c96f7df0.html</url>
    <content><![CDATA[<h1 id="center-博客指路-center"><center><a href="https://www.cnblogs.com/alex-gc/p/11165821.html">博客指路</a></center></h1>
]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>Stable-diffusion-command</title>
    <url>/post/9ba61012.html</url>
    <content><![CDATA[<h3 id="指定服务器调用显卡">指定服务器调用显卡</h3>
<p><code>export CUDA_VISIBLE_DEVICES=1,3</code></p>
<h3 id="export配置环境变量">export配置环境变量</h3>
<h3 id="pip换源">pip换源</h3>
<p>python -m pip config set global.index-url <a href="http://mirrors.cloud.tencent.com/pypi/simple">http://mirrors.cloud.tencent.com/pypi/simple</a></p>
<hr>
<h2 id="一次性打开代理">一次性打开代理</h2>
<p>export http_proxy=http://127.0.0.1:7890<br>
export https_proxy=http://127.0.0.1:7890<br>
export ALL_PROXY=socks5://127.0.0.1:7891</p>
<h2 id="打开代理：">打开代理：</h2>
<p><code>clash -d ~/.config/clash</code></p>
<p>echo $https_proxy</p>
<hr>
<p>如果你想要临时关闭终端会话中的代理设置，可以运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">unset</span> https_proxy http_proxy all_proxy ALL_PROXY</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="关于科学上网：">关于科学上网：</h3>
<p>要设置 <code>https_proxy</code> 环境变量为 <code>http://127.0.0.1:7890</code>，你可以使用以下方式：</p>
<p>临时设置，只在当前终端会话中生效（终端关闭后将失效）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:7890</span><br></pre></td></tr></table></figure>
<p>永久设置，对当前用户在所有终端会话中都生效：</p>
<ol>
<li>打开终端并运行以下命令编辑用户的 <code>~/.bashrc</code> 文件（如果你使用的是 Bash shell）：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nano ~/.bashrc</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>在文件末尾添加以下行：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:7890</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>
<p>按下 <code>Ctrl + O</code> 保存文件，然后按下 <code>Ctrl + X</code> 关闭文本编辑器。</p>
</li>
<li>
<p>使更改生效：</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>这样，在每次打开新终端会话时，<code>https_proxy</code> 环境变量都会被自动设置为 <code>http://127.0.0.1:7890</code>。</p>
<p>请注意，如果你使用的是其他 shell，例如 Zsh，那么相应的配置文件可能不是 <code>~/.bashrc</code>，而是 <code>~/.zshrc</code>。在这种情况下，请将上述步骤中的文件名替换为正确的配置文件名。</p>
<hr>
]]></content>
      <tags>
        <tag>sd</tag>
      </tags>
  </entry>
  <entry>
    <title>linux指令集</title>
    <url>/post/4de2ff1e.html</url>
    <content><![CDATA[<p>常见的Linux操作和命令：</p>
<ol>
<li>
<p><strong>文件和目录操作</strong>：</p>
<ul>
<li><code>ls</code>：列出当前目录的文件和子目录。</li>
<li><code>cd</code>：改变当前工作目录。</li>
<li><code>pwd</code>：显示当前工作目录的完整路径。</li>
<li><code>mkdir</code>：创建新目录。</li>
<li><code>touch</code>：创建新文件。</li>
<li><code>cp</code>：复制文件或目录。</li>
<li><code>mv</code>：移动或重命名文件或目录。</li>
<li><code>rm</code>：删除文件或目录。</li>
</ul>
</li>
<li>
<p><strong>文件查看和编辑</strong>：</p>
<ul>
<li><code>cat</code>：查看文件内容。</li>
<li><code>more</code> 或 <code>less</code>：分页查看文件内容。</li>
<li><code>nano</code> 或 <code>vim</code>：文本编辑器。</li>
<li><code>head</code> 和 <code>tail</code>：查看文件的开头和结尾部分。</li>
</ul>
</li>
<li>
<p><strong>系统信息</strong>：</p>
<ul>
<li><code>uname</code>：显示系统信息。</li>
<li><code>top</code> 或 <code>htop</code>：查看系统资源使用情况。</li>
<li><code>df</code>：显示磁盘空间使用情况。</li>
<li><code>free</code>：显示内存使用情况。</li>
</ul>
</li>
<li>
<p><strong>进程管理</strong>：</p>
<ul>
<li><code>ps</code>：列出当前正在运行的进程。</li>
<li><code>kill</code>：终止进程。</li>
<li><code>bg</code> 和 <code>fg</code>：在后台和前台运行进程。</li>
</ul>
</li>
<li>
<p><strong>用户和权限</strong>：</p>
<ul>
<li><code>sudo</code>：以超级用户权限运行命令。</li>
<li><code>useradd</code> 和 <code>userdel</code>：创建和删除用户。</li>
<li><code>passwd</code>：更改用户密码。</li>
<li><code>chmod</code>：更改文件和目录权限。</li>
<li><code>chown</code>：更改文件和目录的所有者。</li>
</ul>
</li>
<li>
<p><strong>包管理</strong>：</p>
<ul>
<li><code>apt</code> 或 <code>apt-get</code>：Debian/Ubuntu系统的包管理工具。</li>
<li><code>yum</code>：CentOS/RHEL系统的包管理工具。</li>
<li><code>dnf</code>：Fedora系统的包管理工具。</li>
</ul>
</li>
<li>
<p><strong>网络操作</strong>：</p>
<ul>
<li><code>ping</code>：测试与主机的网络连接。</li>
<li><code>ifconfig</code> 或 <code>ip</code>：查看和配置网络接口。</li>
<li><code>ssh</code>：远程登录其他计算机。</li>
<li><code>wget</code> 或 <code>curl</code>：下载文件或内容。</li>
</ul>
</li>
<li>
<p><strong>压缩和解压缩</strong>：</p>
<ul>
<li><code>tar</code>：打包和解包文件。</li>
<li><code>gzip</code> 和 <code>gunzip</code>：压缩和解压缩文件。</li>
<li><code>zip</code> 和 <code>unzip</code>：创建和解压ZIP文件。</li>
</ul>
</li>
<li>
<p><strong>查找文件</strong>：</p>
<ul>
<li><code>find</code>：按名称、类型等条件查找文件。</li>
<li><code>grep</code>：在文本文件中搜索特定字符串。</li>
</ul>
</li>
<li>
<p><strong>系统日志</strong>：</p>
<ul>
<li><code>dmesg</code>：显示系统消息日志。</li>
<li><code>journalctl</code>：查看systemd日志。</li>
</ul>
</li>
</ol>
<p>这只是Linux命令的一小部分，Linux系统非常强大且具有高度可定制性，可以根据需要执行各种任务。要了解有关特定命令的详细信息，你可以在终端中运行<code>man</code>命令，后跟命令名称，以查看其手册页。例如：<code>man ls</code> 或 <code>man mkdir</code>。这将提供有关该命令的详细信息和选项。</p>
]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion入门--inference</title>
    <url>/post/2786a856.html</url>
    <content><![CDATA[<h3 id="本文为diffusion库用于推理的基本介绍-以代码块功能和实现为主">本文为diffusion库用于推理的基本介绍，以代码块功能和实现为主。</h3>
<hr>
<h3 id="三行简化版：">三行简化版：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DiffusionPipeline</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">pipeline = DiffusionPipeline.from_pretrained(<span class="string">&quot;/data1/sdmodels/stable-diffusion-v1-4&quot;</span>, use_safetensors=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">pipeline.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">image = pipeline(<span class="string">&quot;An image of a squirrel in Picasso style&quot;</span>).images[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&quot;/data1/sdtest/&quot;</span></span><br><span class="line">output_filename = <span class="string">&quot;2.1.png&quot;</span></span><br><span class="line">output_path = os.path.join(output_dir, output_filename)</span><br><span class="line">image.save(output_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的图像已保存到:&quot;</span>, output_path)</span><br></pre></td></tr></table></figure>
<p>可以看到核心部分只用pipeline调用一个训练好的模型即可</p>
<hr>
<h3 id="当然我们也可以指定model和scheduler-并且自己生成原始噪声并手动实现循环降噪">当然我们也可以指定model和scheduler，并且自己生成原始噪声并手动实现循环降噪</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DDPMScheduler, UNet2DModel, EulerDiscreteScheduler, UNet2DConditionModel</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DDPMScheduler, UNet2DModel</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#分别指定scheduler和model</span></span><br><span class="line">scheduler = DDPMScheduler.from_pretrained(<span class="string">&quot;google/ddpm-cat-256&quot;</span>)</span><br><span class="line">model = UNet2DModel.from_pretrained(<span class="string">&quot;google/ddpm-cat-256&quot;</span>, use_safetensors=<span class="literal">True</span>).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设定scheduler步数</span></span><br><span class="line">scheduler.set_timesteps(<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#批次大小为1，表示只有一个样本。</span></span><br><span class="line"><span class="comment">#有3个通道，可能表示了一个具有3个颜色通道的图像或者3个特征通道的数据。</span></span><br><span class="line"><span class="comment">#数据的空间维度由sample_size确定，表示了图像的高度和宽度。</span></span><br><span class="line">sample_size = model.config.sample_size</span><br><span class="line">noise = torch.randn((<span class="number">1</span>, <span class="number">3</span>, sample_size, sample_size)).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = noise</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> scheduler.timesteps:</span><br><span class="line">    <span class="comment">#用model预测残余噪声</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        noisy_residual = model(<span class="built_in">input</span>, t).sample</span><br><span class="line">    <span class="comment">#用scheduler实现diffusion反向传播，参数为预测噪声、步数。当前图像</span></span><br><span class="line">    previous_noisy_sample = scheduler.step(noisy_residual, t, <span class="built_in">input</span>).prev_sample</span><br><span class="line">    <span class="built_in">input</span> = previous_noisy_sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">image = (<span class="built_in">input</span> / <span class="number">2</span> + <span class="number">0.5</span>).clamp(<span class="number">0</span>, <span class="number">1</span>).squeeze()</span><br><span class="line">image = (image.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>) * <span class="number">255</span>).<span class="built_in">round</span>().to(torch.uint8).cpu().numpy()</span><br><span class="line">image = Image.fromarray(image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图像数据保存为图像文件</span></span><br><span class="line">output_dir = <span class="string">&quot;/data1/sdtest/&quot;</span></span><br><span class="line">output_filename = <span class="string">&quot;2.1.png&quot;</span></span><br><span class="line">output_path = os.path.join(output_dir, output_filename)</span><br><span class="line">image.save(output_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的图像已保存到:&quot;</span>, output_path)</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="关于图像转换的一点补充：">关于图像转换的一点补充：</h4>
<p>将一个PyTorch张量（<code>input</code>）转换为一个NumPy数组，然后再将其转换为PIL（Python Imaging Library）图像对象。让我来解释每一行代码的作用：</p>
<ol>
<li>
<p><code>image = (input / 2 + 0.5).clamp(0, 1).squeeze()</code></p>
<ul>
<li><code>input</code>是一个PyTorch张量，假设其值范围在[-1, 1]之间。</li>
<li><code>(input / 2 + 0.5)</code>：这一步将输入张量的值从范围[-1, 1]线性映射到[0, 1]范围内。</li>
<li><code>.clamp(0, 1)</code>：这一步确保所有的值都在[0, 1]之间，即截断小于0和大于1的值。</li>
<li><code>.squeeze()</code>：如果输入张量的形状中存在大小为1的维度，这一步将其挤压掉，使得输出张量的维度更紧凑。</li>
</ul>
</li>
<li>
<p><code>image = (image.permute(1, 2, 0) * 255).round().to(torch.uint8).cpu().numpy()</code></p>
<ul>
<li><code>image.permute(1, 2, 0)</code>：这一步对<code>image</code>张量的维度进行重排列，将通道维度移到最后一个维度上。这通常是由于PIL图像和NumPy数组的通道顺序不同。</li>
<li><code>* 255</code>：将所有像素值乘以255，将像素值缩放到0-255的整数范围内。</li>
<li><code>.round()</code>：四舍五入将浮点数像素值转换为整数像素值。</li>
<li><code>.to(torch.uint8)</code>：将张量的数据类型转换为无符号8位整数，以确保数值范围在0-255之间。</li>
<li><code>.cpu().numpy()</code>：将PyTorch张量转换为NumPy数组。</li>
</ul>
</li>
<li>
<p><code>image = Image.fromarray(image)</code></p>
<ul>
<li><code>Image.fromarray(image)</code>：这一步将NumPy数组转换为PIL图像对象，使得你可以使用PIL库的功能来处理和显示图像。</li>
</ul>
</li>
</ol>
<p>总之，这段代码的目的是将一个经过处理的PyTorch张量（通常代表图像数据）转换为PIL图像对象，以便进行后续的图像处理或显示。</p>
<hr>
<h3 id="插播sdxl的基本实现">插播sdxl的基本实现</h3>
<p>sdxl因为base&amp;refine机制的引入实现机制相对复杂，这里仅提供基础写法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DiffusionPipeline</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="comment"># load both base &amp; refiner</span></span><br><span class="line">base = DiffusionPipeline.from_pretrained(</span><br><span class="line">    <span class="string">&quot;/data1/sdmodels/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="string">&quot;fp16&quot;</span>, use_safetensors=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">base.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">refiner = DiffusionPipeline.from_pretrained(</span><br><span class="line">    <span class="string">&quot;/data1/sdmodels/stable-diffusion-xl-refiner-1.0&quot;</span>,</span><br><span class="line">    text_encoder_2=base.text_encoder_2,</span><br><span class="line">    vae=base.vae,</span><br><span class="line">    torch_dtype=torch.float16,</span><br><span class="line">    use_safetensors=<span class="literal">True</span>,</span><br><span class="line">    variant=<span class="string">&quot;fp16&quot;</span>,</span><br><span class="line">)</span><br><span class="line">refiner.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define how many steps and what % of steps to be run on each experts (80/20) here</span></span><br><span class="line">n_steps = <span class="number">40</span></span><br><span class="line">high_noise_frac = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">prompt = <span class="string">&quot;1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt,high quality,masterpiece&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># run both experts</span></span><br><span class="line">image = base(</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    num_inference_steps=n_steps,</span><br><span class="line">    denoising_end=high_noise_frac,</span><br><span class="line">    output_type=<span class="string">&quot;latent&quot;</span>,</span><br><span class="line">).images</span><br><span class="line">image = refiner(</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    num_inference_steps=n_steps,</span><br><span class="line">    denoising_start=high_noise_frac,</span><br><span class="line">    image=image,</span><br><span class="line">).images[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&quot;/data1/sdtest/&quot;</span></span><br><span class="line">output_filename = <span class="string">&quot;2.1.png&quot;</span></span><br><span class="line">output_path = os.path.join(output_dir, output_filename)</span><br><span class="line"><span class="comment"># 将图像数据保存为图像文件</span></span><br><span class="line">image.save(output_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的图像已保存到:&quot;</span>, output_path)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="当然有时我们希望能批量出图-并且可以调整整个图模型的各种参数-比如size-step-number等等">当然有时我们希望能批量出图，并且可以调整整个图模型的各种参数，比如size，step_number等等。</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DiffusionPipeline, StableDiffusionPipeline</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> EulerDiscreteScheduler</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> CLIPImageProcessor</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DPMSolverMultistepScheduler</span><br><span class="line"><span class="keyword">from</span> diffusers.utils <span class="keyword">import</span> make_image_grid</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> AutoencoderKL</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&quot;/data1/sdmodels/stable-diffusion-xl-base-1.0&quot;</span></span><br><span class="line">prompt = <span class="string">&quot;1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt,high quality,masterpiece&quot;</span></span><br><span class="line">num_inference_steps = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用fp16降低精度几乎不影响出图质量且可以节省大量显存并提速</span></span><br><span class="line">pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=<span class="literal">True</span>, variant=<span class="string">&quot;fp16&quot;</span>, safety_checker=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">pipe.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="comment"># pipe.enable_xformers_memory_efficient_attention()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为模型选定随机种子</span></span><br><span class="line">generator = torch.Generator(<span class="string">&quot;cuda&quot;</span>).manual_seed(np.random.randint(<span class="number">0</span>, <span class="number">114514</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)</span></span><br><span class="line">pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)</span><br><span class="line"><span class="comment"># pipe.enable_xformers_memory_efficient_attention()</span></span><br><span class="line"><span class="comment"># image = pipe(prompt, generator=generator, height=1024, width=1024,num_inference_steps=num_inference_steps).images[0]</span></span><br><span class="line"><span class="comment"># vae = AutoencoderKL.from_pretrained(</span></span><br><span class="line"><span class="comment">#   &quot;stabilityai/sdxl-vae&quot;, torch_dtype=torch.float16).to(&quot;cuda&quot;)</span></span><br><span class="line"><span class="comment"># pipe.vae = vae</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量出图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_inputs</span>(<span class="params">batch_size</span>):</span><br><span class="line">    generator = [torch.Generator(<span class="string">&quot;cuda&quot;</span>).manual_seed(np.random.randint(<span class="number">0</span>, <span class="number">114514</span>))</span><br><span class="line">                 <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)]</span><br><span class="line">    prompts = batch_size * [prompt]  <span class="comment">#批量prompt</span></span><br><span class="line">    num_inference_steps = <span class="number">20</span>  <span class="comment">#推理步数</span></span><br><span class="line">    height = <span class="number">512</span></span><br><span class="line">    width = <span class="number">512</span> <span class="comment">#size</span></span><br><span class="line">    guidance_scale = <span class="number">7.5</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;prompt&quot;</span>: prompts, <span class="string">&quot;generator&quot;</span>: generator, <span class="string">&quot;num_inference_steps&quot;</span>: num_inference_steps, <span class="string">&quot;height&quot;</span>: height, <span class="string">&quot;width&quot;</span>: width, <span class="string">&quot;guidance_scale&quot;</span>: guidance_scale&#125;</span><br><span class="line"><span class="comment">#提示词（prompt）</span></span><br><span class="line"><span class="comment">#负面词（negative_prompt）</span></span><br><span class="line"><span class="comment">#图片宽高（width, height）</span></span><br><span class="line"><span class="comment">#采样步数（num_inference_steps）</span></span><br><span class="line"><span class="comment">#引导强度（guidance_scale）</span></span><br><span class="line"><span class="comment">#生成张数（num_images_per_prompt）</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pipe.enable_attention_slicing()</span><br><span class="line"></span><br><span class="line"><span class="comment">#一次生成4张图片并且以2*2的方式以网格的形式保存</span></span><br><span class="line">images = pipe(**get_inputs(batch_size=<span class="number">4</span>)).images</span><br><span class="line">grid = make_image_grid(images, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save the image in the specified directory</span></span><br><span class="line"><span class="comment"># 选择一个文件保存路径</span></span><br><span class="line">output_dir = <span class="string">&quot;/data1/sdtest/&quot;</span></span><br><span class="line">output_filename = <span class="string">&quot;2.1.png&quot;</span></span><br><span class="line">output_path = os.path.join(output_dir, output_filename)</span><br><span class="line"><span class="comment"># 将图像数据保存为图像文件</span></span><br><span class="line">grid.save(output_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的图像已保存到:&quot;</span>, output_path)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="最后我们希望sd的所有部分都可以自己实现包括encoder-decoder-latent-voe等">最后我们希望sd的所有部分都可以自己实现包括encoder/decoder/latent/voe等</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> UniPCMultistepScheduler</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> CLIPTextModel, CLIPTokenizer</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> AutoencoderKL, UNet2DConditionModel, PNDMScheduler</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#sd几大模块的设定</span></span><br><span class="line">vae = AutoencoderKL.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;vae&quot;</span>, use_safetensors=<span class="literal">True</span>)</span><br><span class="line">tokenizer = CLIPTokenizer.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;tokenizer&quot;</span>)</span><br><span class="line">text_encoder = CLIPTextModel.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;text_encoder&quot;</span>, use_safetensors=<span class="literal">True</span>)</span><br><span class="line">unet = UNet2DConditionModel.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;unet&quot;</span>, use_safetensors=<span class="literal">True</span>)</span><br><span class="line">scheduler = UniPCMultistepScheduler.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;scheduler&quot;</span>)</span><br><span class="line"></span><br><span class="line">torch_device = <span class="string">&quot;cuda&quot;</span></span><br><span class="line">vae.to(torch_device)</span><br><span class="line">text_encoder.to(torch_device)</span><br><span class="line">unet.to(torch_device)</span><br><span class="line"></span><br><span class="line">prompt = [<span class="string">&quot;1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt,high quality,masterpiece&quot;</span>]</span><br><span class="line">height = <span class="number">512</span>  <span class="comment"># default height of Stable Diffusion</span></span><br><span class="line">width = <span class="number">512</span>  <span class="comment"># default width of Stable Diffusion</span></span><br><span class="line">num_inference_steps = <span class="number">25</span>  <span class="comment"># Number of denoising steps</span></span><br><span class="line">guidance_scale = <span class="number">7.5</span>  <span class="comment"># Scale for classifier-free guidance</span></span><br><span class="line"><span class="comment"># Seed generator to create the inital latent noise</span></span><br><span class="line">generator = torch.manual_seed(<span class="number">0</span>)</span><br><span class="line">batch_size = <span class="built_in">len</span>(prompt)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">text_input = tokenizer(</span><br><span class="line">    prompt, padding=<span class="string">&quot;max_length&quot;</span>, max_length=tokenizer.model_max_length, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">max_length = text_input.input_ids.shape[-<span class="number">1</span>]</span><br><span class="line">uncond_input = tokenizer([<span class="string">&quot;&quot;</span>] * batch_size, padding=<span class="string">&quot;max_length&quot;</span>,max_length=max_length, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">text_embeddings = torch.cat([uncond_embeddings, text_embeddings])</span><br><span class="line"></span><br><span class="line">latents = torch.randn(</span><br><span class="line">    (batch_size, unet.in_channels, height // <span class="number">8</span>, width // <span class="number">8</span>),</span><br><span class="line">    generator=generator,</span><br><span class="line">)</span><br><span class="line">latents = latents.to(torch_device)</span><br><span class="line"></span><br><span class="line">latents = latents * scheduler.init_noise_sigma</span><br><span class="line"></span><br><span class="line">scheduler.set_timesteps(num_inference_steps)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> tqdm(scheduler.timesteps):</span><br><span class="line">    <span class="comment"># expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.</span></span><br><span class="line">    latent_model_input = torch.cat([latents] * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    latent_model_input = scheduler.scale_model_input(</span><br><span class="line">        latent_model_input, timestep=t)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># predict the noise residual</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        noise_pred = unet(latent_model_input, t,</span><br><span class="line">                          encoder_hidden_states=text_embeddings).sample</span><br><span class="line"></span><br><span class="line">    <span class="comment"># perform guidance</span></span><br><span class="line">    noise_pred_uncond, noise_pred_text = noise_pred.chunk(<span class="number">2</span>)</span><br><span class="line">    noise_pred = noise_pred_uncond + guidance_scale * \</span><br><span class="line">        (noise_pred_text - noise_pred_uncond)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the previous noisy sample x_t -&gt; x_t-1</span></span><br><span class="line">    latents = scheduler.step(noise_pred, t, latents).prev_sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># scale and decode the image latents with vae</span></span><br><span class="line">latents = <span class="number">1</span> / <span class="number">0.18215</span> * latents</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    image = vae.decode(latents).sample</span><br><span class="line"></span><br><span class="line">image = (image / <span class="number">2</span> + <span class="number">0.5</span>).clamp(<span class="number">0</span>, <span class="number">1</span>).squeeze()</span><br><span class="line">image = (image.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>) * <span class="number">255</span>).to(torch.uint8).cpu().numpy()</span><br><span class="line">images = (image * <span class="number">255</span>).<span class="built_in">round</span>().astype(<span class="string">&quot;uint8&quot;</span>)</span><br><span class="line">image = Image.fromarray(image)</span><br><span class="line">output_dir = <span class="string">&quot;/data1/sdtest/&quot;</span></span><br><span class="line">output_filename = <span class="string">&quot;2.1.png&quot;</span></span><br><span class="line">output_path = os.path.join(output_dir, output_filename)</span><br><span class="line"><span class="comment"># 将图像数据保存为图像文件</span></span><br><span class="line">image.save(output_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的图像已保存到:&quot;</span>, output_path)</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>diffusion</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion入门--training</title>
    <url>/post/e5691.html</url>
    <content><![CDATA[<p>本文介绍有关<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>i</mi><mi>f</mi><mi>f</mi><mi>u</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">diffusion</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span></span></span></span>训练的相关</p>
<hr>
<h3 id="给定数据集进行训练">给定数据集进行训练</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> HfFolder, Repository, whoami</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> notebook_launcher</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> diffusers.utils <span class="keyword">import</span> make_image_grid</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DDPMPipeline</span><br><span class="line"><span class="keyword">from</span> diffusers.optimization <span class="keyword">import</span> get_cosine_schedule_with_warmup</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DDPMScheduler</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> UNet2DModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> HfFolder, Repository, whoami</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TrainingConfig</span>:</span><br><span class="line">    image_size = <span class="number">128</span>  <span class="comment"># the generated image resolution</span></span><br><span class="line">    train_batch_size = <span class="number">16</span></span><br><span class="line">    eval_batch_size = <span class="number">16</span>  <span class="comment"># how many images to sample during evaluation</span></span><br><span class="line">    num_epochs = <span class="number">50</span></span><br><span class="line">    gradient_accumulation_steps = <span class="number">1</span></span><br><span class="line">    learning_rate = <span class="number">1e-4</span></span><br><span class="line">    lr_warmup_steps = <span class="number">500</span></span><br><span class="line">    save_image_epochs = <span class="number">3</span></span><br><span class="line">    save_model_epochs = <span class="number">30</span></span><br><span class="line">    mixed_precision = <span class="string">&quot;fp16&quot;</span>  <span class="comment"># `no` for float32, `fp16` for automatic mixed precision</span></span><br><span class="line">    output_dir = <span class="string">&quot;ddpm-butterflies-128&quot;</span>  <span class="comment"># the model name locally and on the HF Hub</span></span><br><span class="line"></span><br><span class="line">    push_to_hub = <span class="literal">False</span>  <span class="comment"># whether to upload the saved model to the HF Hub</span></span><br><span class="line">    hub_private_repo = <span class="literal">False</span></span><br><span class="line">    overwrite_output_dir = <span class="literal">True</span>  <span class="comment"># overwrite the old model when re-running the notebook</span></span><br><span class="line">    seed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">config = TrainingConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">config.dataset_name = <span class="string">&quot;huggan/smithsonian_butterflies_subset&quot;</span></span><br><span class="line">dataset = load_dataset(config.dataset_name, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">4</span>, figsize=(<span class="number">16</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset[:<span class="number">4</span>][<span class="string">&quot;image&quot;</span>]):</span><br><span class="line">    axs[i].imshow(image)</span><br><span class="line">    axs[i].set_axis_off()</span><br><span class="line">fig.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">preprocess = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">        transforms.Resize((config.image_size, config.image_size)),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>]),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">examples</span>):</span><br><span class="line">    images = [preprocess(image.convert(<span class="string">&quot;RGB&quot;</span>)) <span class="keyword">for</span> image <span class="keyword">in</span> examples[<span class="string">&quot;image&quot;</span>]]</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;images&quot;</span>: images&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset.set_transform(transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig, axs = plt.subplots(1, 4, figsize=(16, 4))</span></span><br><span class="line"><span class="comment"># for i, image in enumerate(dataset[:4][&quot;image&quot;]):</span></span><br><span class="line"><span class="comment">#    axs[i].imshow(image)</span></span><br><span class="line"><span class="comment">#    axs[i].set_axis_off()</span></span><br><span class="line"><span class="comment"># fig.show()</span></span><br><span class="line"></span><br><span class="line">train_dataloader = torch.utils.data.DataLoader(</span><br><span class="line">    dataset, batch_size=config.train_batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = UNet2DModel(</span><br><span class="line">    sample_size=config.image_size,  <span class="comment"># the target image resolution</span></span><br><span class="line">    in_channels=<span class="number">3</span>,  <span class="comment"># the number of input channels, 3 for RGB images</span></span><br><span class="line">    out_channels=<span class="number">3</span>,  <span class="comment"># the number of output channels</span></span><br><span class="line">    layers_per_block=<span class="number">2</span>,  <span class="comment"># how many ResNet layers to use per UNet block</span></span><br><span class="line">    <span class="comment"># the number of output channels for each UNet block</span></span><br><span class="line">    block_out_channels=(<span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">    down_block_types=(</span><br><span class="line">        <span class="string">&quot;DownBlock2D&quot;</span>,  <span class="comment"># a regular ResNet downsampling block</span></span><br><span class="line">        <span class="string">&quot;DownBlock2D&quot;</span>,</span><br><span class="line">        <span class="string">&quot;DownBlock2D&quot;</span>,</span><br><span class="line">        <span class="string">&quot;DownBlock2D&quot;</span>,</span><br><span class="line">        <span class="string">&quot;AttnDownBlock2D&quot;</span>,  <span class="comment"># a ResNet downsampling block with spatial self-attention</span></span><br><span class="line">        <span class="string">&quot;DownBlock2D&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    up_block_types=(</span><br><span class="line">        <span class="string">&quot;UpBlock2D&quot;</span>,  <span class="comment"># a regular ResNet upsampling block</span></span><br><span class="line">        <span class="string">&quot;AttnUpBlock2D&quot;</span>,  <span class="comment"># a ResNet upsampling block with spatial self-attention</span></span><br><span class="line">        <span class="string">&quot;UpBlock2D&quot;</span>,</span><br><span class="line">        <span class="string">&quot;UpBlock2D&quot;</span>,</span><br><span class="line">        <span class="string">&quot;UpBlock2D&quot;</span>,</span><br><span class="line">        <span class="string">&quot;UpBlock2D&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sample_image = dataset[<span class="number">0</span>][<span class="string">&quot;images&quot;</span>].unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Input shape:&quot;</span>, sample_image.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output shape:&quot;</span>, model(sample_image, timestep=<span class="number">0</span>).sample.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">noise_scheduler = DDPMScheduler(num_train_timesteps=<span class="number">1000</span>)</span><br><span class="line">noise = torch.randn(sample_image.shape)</span><br><span class="line">timesteps = torch.LongTensor([<span class="number">50</span>])</span><br><span class="line">noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Image.fromarray(((noisy_image.permute(0, 2, 3, 1) + 1.0) * 127.5).type(torch.uint8).numpy()[0])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">noise_pred = model(noisy_image, timesteps).sample</span><br><span class="line">loss = F.mse_loss(noise_pred, noise)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)</span><br><span class="line">lr_scheduler = get_cosine_schedule_with_warmup(</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    num_warmup_steps=config.lr_warmup_steps,</span><br><span class="line">    num_training_steps=(<span class="built_in">len</span>(train_dataloader) * config.num_epochs),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">config, epoch, pipeline</span>):</span><br><span class="line">    <span class="comment"># Sample some images from random noise (this is the backward diffusion process).</span></span><br><span class="line">    <span class="comment"># The default pipeline output type is `List[PIL.Image]`</span></span><br><span class="line">    images = pipeline(</span><br><span class="line">        batch_size=config.eval_batch_size,</span><br><span class="line">        generator=torch.manual_seed(config.seed),</span><br><span class="line">    ).images</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Make a grid out of the images</span></span><br><span class="line">    image_grid = make_image_grid(images, rows=<span class="number">4</span>, cols=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the images</span></span><br><span class="line">    test_dir = os.path.join(config.output_dir, <span class="string">&quot;samples&quot;</span>)</span><br><span class="line">    os.makedirs(test_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    image_grid.save(<span class="string">f&quot;<span class="subst">&#123;test_dir&#125;</span>/<span class="subst">&#123;epoch:04d&#125;</span>.png&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_full_repo_name</span>(<span class="params">model_id: <span class="built_in">str</span>, organization: <span class="built_in">str</span> = <span class="literal">None</span>, token: <span class="built_in">str</span> = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> token <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        token = HfFolder.get_token()</span><br><span class="line">    <span class="keyword">if</span> organization <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        username = whoami(token)[<span class="string">&quot;name&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;username&#125;</span>/<span class="subst">&#123;model_id&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;organization&#125;</span>/<span class="subst">&#123;model_id&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_loop</span>(<span class="params">config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler</span>):</span><br><span class="line">    <span class="comment"># Initialize accelerator and tensorboard logging</span></span><br><span class="line">    accelerator = Accelerator(</span><br><span class="line">        mixed_precision=config.mixed_precision,</span><br><span class="line">        gradient_accumulation_steps=config.gradient_accumulation_steps,</span><br><span class="line">        log_with=<span class="string">&quot;tensorboard&quot;</span>,</span><br><span class="line">        project_dir=os.path.join(config.output_dir, <span class="string">&quot;logs&quot;</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> accelerator.is_main_process:</span><br><span class="line">        <span class="keyword">if</span> config.push_to_hub:</span><br><span class="line">            repo_name = get_full_repo_name(Path(config.output_dir).name)</span><br><span class="line">            repo = Repository(config.output_dir, clone_from=repo_name)</span><br><span class="line">        <span class="keyword">elif</span> config.output_dir <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            os.makedirs(config.output_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        accelerator.init_trackers(<span class="string">&quot;train_example&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Prepare everything</span></span><br><span class="line">    <span class="comment"># There is no specific order to remember, you just need to unpack the</span></span><br><span class="line">    <span class="comment"># objects in the same order you gave them to the prepare method.</span></span><br><span class="line">    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(</span><br><span class="line">        model, optimizer, train_dataloader, lr_scheduler</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    global_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Now you train the model</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.num_epochs):</span><br><span class="line">        progress_bar = tqdm(total=<span class="built_in">len</span>(train_dataloader),</span><br><span class="line">                            disable=<span class="keyword">not</span> accelerator.is_local_main_process)</span><br><span class="line">        progress_bar.set_description(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">            clean_images = batch[<span class="string">&quot;images&quot;</span>]</span><br><span class="line">            <span class="comment"># Sample noise to add to the images</span></span><br><span class="line">            noise = torch.randn(clean_images.shape).to(clean_images.device)</span><br><span class="line">            bs = clean_images.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Sample a random timestep for each image</span></span><br><span class="line">            timesteps = torch.randint(</span><br><span class="line">                <span class="number">0</span>, noise_scheduler.config.num_train_timesteps, (bs,), device=clean_images.device</span><br><span class="line">            ).long()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Add noise to the clean images according to the noise magnitude at each timestep</span></span><br><span class="line">            <span class="comment"># (this is the forward diffusion process)</span></span><br><span class="line">            noisy_images = noise_scheduler.add_noise(</span><br><span class="line">                clean_images, noise, timesteps)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> accelerator.accumulate(model):</span><br><span class="line">                <span class="comment"># Predict the noise residual</span></span><br><span class="line">                noise_pred = model(noisy_images, timesteps,</span><br><span class="line">                                   return_dict=<span class="literal">False</span>)[<span class="number">0</span>]</span><br><span class="line">                loss = F.mse_loss(noise_pred, noise)</span><br><span class="line">                accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">                accelerator.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">                optimizer.step()</span><br><span class="line">                lr_scheduler.step()</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            progress_bar.update(<span class="number">1</span>)</span><br><span class="line">            logs = &#123;<span class="string">&quot;loss&quot;</span>: loss.detach().item(), <span class="string">&quot;lr&quot;</span>: lr_scheduler.get_last_lr()[</span><br><span class="line">                <span class="number">0</span>], <span class="string">&quot;step&quot;</span>: global_step&#125;</span><br><span class="line">            progress_bar.set_postfix(**logs)</span><br><span class="line">            accelerator.log(logs, step=global_step)</span><br><span class="line">            global_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># After each epoch you optionally sample some demo images with evaluate() and save the model</span></span><br><span class="line">        <span class="keyword">if</span> accelerator.is_main_process:</span><br><span class="line">            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(</span><br><span class="line">                model), scheduler=noise_scheduler)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (epoch + <span class="number">1</span>) % config.save_image_epochs == <span class="number">0</span> <span class="keyword">or</span> epoch == config.num_epochs - <span class="number">1</span>:</span><br><span class="line">                evaluate(config, epoch, pipeline)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (epoch + <span class="number">1</span>) % config.save_model_epochs == <span class="number">0</span> <span class="keyword">or</span> epoch == config.num_epochs - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> config.push_to_hub:</span><br><span class="line">                    repo.push_to_hub(</span><br><span class="line">                        commit_message=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>&quot;</span>, blocking=<span class="literal">True</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    pipeline.save_pretrained(config.output_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">args = (config, model, noise_scheduler,</span><br><span class="line">        optimizer, train_dataloader, lr_scheduler)</span><br><span class="line"></span><br><span class="line">notebook_launcher(train_loop, args, num_processes=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sample_images = <span class="built_in">sorted</span>(glob.glob(<span class="string">f&quot;<span class="subst">&#123;config.output_dir&#125;</span>/samples/*.png&quot;</span>))</span><br><span class="line">Image.<span class="built_in">open</span>(sample_images[-<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="给定lora模型直接加载使用">给定lora模型直接加载使用</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub.repocard <span class="keyword">import</span> RepoCard</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DiffusionPipeline, StableDiffusionPipeline</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> EulerDiscreteScheduler</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> CLIPImageProcessor</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DPMSolverMultistepScheduler</span><br><span class="line"><span class="keyword">from</span> diffusers.utils <span class="keyword">import</span> make_image_grid</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> AutoencoderKL</span><br><span class="line"></span><br><span class="line"><span class="comment">#直接加载现成的lora仓库</span></span><br><span class="line">lora_model_id = <span class="string">&quot;sayakpaul/sd-model-finetuned-lora-t4&quot;</span></span><br><span class="line">card = RepoCard.load(lora_model_id)</span><br><span class="line">base_model_id = card.data.to_dict()[<span class="string">&quot;base_model&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(base_model_id)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pipe = StableDiffusionPipeline.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, torch_dtype=torch.float16, use_safetensors=<span class="literal">True</span>)</span><br><span class="line">pipe.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">image = pipe(<span class="string">&quot;pokeman&quot;</span>, num_inference_steps=<span class="number">25</span>, guidance_scale=<span class="number">7.5</span>).images[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># save the image in the specified directory</span></span><br><span class="line"><span class="comment"># 选择一个文件保存路径</span></span><br><span class="line">output_dir = <span class="string">&quot;/data1/sdtest/&quot;</span></span><br><span class="line">output_filename = <span class="string">&quot;3.1.png&quot;</span></span><br><span class="line">output_path = os.path.join(output_dir, output_filename)</span><br><span class="line"><span class="comment"># 将图像数据保存为图像文件</span></span><br><span class="line">image.save(output_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的图像已保存到:&quot;</span>, output_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="利用数据集自己训练lora并使用">利用数据集自己训练lora并使用</h3>
<p>这里是直接用的别人的训练集</p>
<p>Specify the MODEL_NAME environment variable (either a Hub model repository id or a path to the directory containing the model weights) and pass it to the pretrained_model_name_or_path argument. You’ll also need to set the DATASET_NAME environment variable to the name of the dataset you want to train on. To use your own dataset, take a look at the Create a dataset for training guide.</p>
<p>The OUTPUT_DIR and HUB_MODEL_ID variables are optional and specify where to save the model to on the Hub:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模型名称</span></span><br><span class="line">export MODEL_NAME=<span class="string">&quot;runwayml/stable-diffusion-v1-5&quot;</span></span><br><span class="line"><span class="comment">#lora输出文件位置</span></span><br><span class="line">export OUTPUT_DIR=<span class="string">&quot;/sddata/finetune/lora/pokemon&quot;</span></span><br><span class="line"><span class="comment">#同步到hub的id</span></span><br><span class="line">export HUB_MODEL_ID=<span class="string">&quot;pokemon-lora&quot;</span></span><br><span class="line"><span class="comment">#dateset名字</span></span><br><span class="line">export DATASET_NAME=<span class="string">&quot;lambdalabs/pokemon-blip-captions&quot;</span></span><br><span class="line"></span><br><span class="line">accelerate launch --mixed_precision=<span class="string">&quot;fp16&quot;</span>  train_text_to_image_lora.py \</span><br><span class="line">  --pretrained_model_name_or_path=$MODEL_NAME \</span><br><span class="line">  --dataset_name=$DATASET_NAME \</span><br><span class="line">  --dataloader_num_workers=<span class="number">8</span> \</span><br><span class="line">  --resolution=<span class="number">512</span> --center_crop --random_flip \</span><br><span class="line">  --train_batch_size=<span class="number">1</span> \</span><br><span class="line">  --gradient_accumulation_steps=<span class="number">4</span> \</span><br><span class="line">  --max_train_steps=<span class="number">15000</span> \</span><br><span class="line">  --learning_rate=<span class="number">1e-04</span> \</span><br><span class="line">  --max_grad_norm=<span class="number">1</span> \</span><br><span class="line">  --lr_scheduler=<span class="string">&quot;cosine&quot;</span> --lr_warmup_steps=<span class="number">0</span> \</span><br><span class="line">  --output_dir=$&#123;OUTPUT_DIR&#125; \</span><br><span class="line">  --push_to_hub \</span><br><span class="line">  --hub_model_id=$&#123;HUB_MODEL_ID&#125; \</span><br><span class="line">  --report_to=wandb \</span><br><span class="line">  --checkpointing_steps=<span class="number">500</span> \</span><br><span class="line">  --validation_prompt=<span class="string">&quot;A pokemon with blue eyes.&quot;</span> \</span><br><span class="line">  --seed=<span class="number">1337</span></span><br></pre></td></tr></table></figure>
<p>There are some flags to be aware of before you start training:</p>
<ul>
<li>–push_to_hub stores the trained LoRA embeddings on the Hub.</li>
<li>–report_to=wandb reports and logs the training results to your Weights &amp; Biases dashboard (as an example, take a look at this report).</li>
<li>–learning_rate=1e-04, you can afford to use a higher learning rate than you normally would with LoRA.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> StableDiffusionPipeline, DPMSolverMultistepScheduler</span><br><span class="line"></span><br><span class="line">model_base = <span class="string">&quot;runwayml/stable-diffusion-v1-5&quot;</span></span><br><span class="line"></span><br><span class="line">pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16, use_safetensors=<span class="literal">True</span>)</span><br><span class="line">pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)</span><br><span class="line"></span><br><span class="line">lora_model_path=<span class="string">&quot;/data1/sdtest/lora-test/diffusers/examples/text_to_image/data1/sdtest/sddata/finetune/lora/pokemon/&quot;</span></span><br><span class="line"></span><br><span class="line">pipe.unet.load_attn_procs(lora_model_path)</span><br><span class="line">pipe.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过cross_attention_kwargs参数指定lora的系数占比</span></span><br><span class="line">image = pipe(</span><br><span class="line">    <span class="string">&quot;pokemon&quot;</span>, num_inference_steps=<span class="number">25</span>, guidance_scale=<span class="number">7.5</span>, cross_attention_kwargs=&#123;<span class="string">&quot;scale&quot;</span>: <span class="number">0.3</span>&#125;</span><br><span class="line">).images[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#image = pipe(&quot;A pokemon with blue eyes.&quot;, num_inference_steps=25, guidance_scale=7.5).images[0]</span></span><br><span class="line">image.save(<span class="string">&quot;blue_pokemon.png&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>diffusion</tag>
      </tags>
  </entry>
</search>
